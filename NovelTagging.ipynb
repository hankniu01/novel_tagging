{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme ACL 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1前言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1,1课程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/overall.png' width=\"800\" height=\"800\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.1 Tagging Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/over_all_1.png' width=\"800\" height=\"800\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/over_all_2.png' width=\"800\" height=\"800\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 代码结构展示\n",
    "<img src=\"./imgs/dir.png\"  width=\"200\" height=\"200\" align=\"bottom\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 准备工作\n",
    "### 2.1项目环境配置\n",
    "\n",
    "* Python3.8\n",
    "* jupyter notebook\n",
    "* torch            1.6.0+cu10.2\n",
    "* numpy            1.18.5\n",
    "\n",
    "代码运行环境建议使用Visual Studio Code(VScode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据集下载\n",
    "* 数据集下载地址：<br>\n",
    " https://pan.baidu.com/s/12maQjrRjv52dPcTA4dRtyw <br>\n",
    " 提取码：bv71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 项目代码结构（VScode中演示）\n",
    "\n",
    ">1）是什么？\n",
    "\n",
    "　　我们首先会在VScode环境中让代码跑一下，直观感受到项目的训练，并展示前向推断的输出，让大家看到模型的效果。\n",
    ">2）怎么构成的？\n",
    "\n",
    "　　然后介绍项目代码的构成，介绍项目有哪些文件夹，包含哪些文件，这些文件构成了什么功能模块如：数据预处理模块，模型设计模块，损失函数模块，推断与评估模块。\n",
    ">3）小结\n",
    "\n",
    "　　在主文件中在过一下启动训练的流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 算法模块及细节（jupyter和VScode中演示）\n",
    "\n",
    "　　在jupyter notebook中细致地讲解每一个模块。\n",
    "  \n",
    "　　以实现模块功能为目的，来讲解每个函数的执行流程，呈现中间数据，方便同学们理解学习。\n",
    "  \n",
    "　　内容分为以下几个模块：**超参数设置，数据读取与处理，模型定义，模型训练，模型评价**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47463, 300])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from utils import *\n",
    "from torch.utils.data.dataset import *\n",
    "from torch.utils.data.sampler import *\n",
    "from torch.nn.utils.rnn import *\n",
    "import bisect\n",
    "from model import *\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--weight'], dest='weight', nargs=None, const=None, default=10.0, type=<class 'float'>, choices=None, help='manual rescaling weight given to each tag except \"O\"', metavar=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Joint Extraction of Entities and Relations\")\n",
    "parser.add_argument('--batch_size', type=int, default=32, metavar='N',\n",
    "                    help='batch size (default: 32)')\n",
    "parser.add_argument('--cuda', action='store_false',\n",
    "                    help='use CUDA (default: True)')\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='dropout applied to layers (default: 0.5)')\n",
    "parser.add_argument('--emb_dropout', type=float, default=0.25,\n",
    "                    help='dropout applied to the embedded layer (default: 0.25)')\n",
    "parser.add_argument('--clip', type=float, default=0.35,\n",
    "                    help='gradient clip, -1 means no clip (default: 0.35)')\n",
    "parser.add_argument('--epochs', type=int, default=30,\n",
    "                    help='upper epoch limit (default: 30)')\n",
    "parser.add_argument('--char_kernel_size', type=int, default=3,\n",
    "                    help='character-level kernel size (default: 3)')\n",
    "parser.add_argument('--word_kernel_size', type=int, default=3,\n",
    "                    help='word-level kernel size (default: 3)')\n",
    "parser.add_argument('--emsize', type=int, default=50,\n",
    "                    help='size of character embeddings (default: 50)')\n",
    "parser.add_argument('--char_layers', type=int, default=3,\n",
    "                    help='# of character-level convolution layers (default: 3)')\n",
    "parser.add_argument('--word_layers', type=int, default=3,\n",
    "                    help='# of word-level convolution layers (default: 3)')\n",
    "parser.add_argument('--char_nhid', type=int, default=50,\n",
    "                    help='number of hidden units per character-level convolution layer (default: 50)')\n",
    "parser.add_argument('--word_nhid', type=int, default=300,\n",
    "                    help='number of hidden units per word-level convolution layer (default: 300)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='report interval (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=4,\n",
    "                    help='initial learning rate (default: 4)')\n",
    "parser.add_argument('--optim', type=str, default='SGD',\n",
    "                    help='optimizer type (default: SGD)')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed (default: 1111)')\n",
    "parser.add_argument('--save', type=str, default='model.pt',\n",
    "                    help='path to save the final model')\n",
    "parser.add_argument('--weight', type=float, default=10.0,\n",
    "                    help='manual rescaling weight given to each tag except \"O\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, char_kernel_size=3, char_layers=3, char_nhid=50, clip=0.35, cuda=True, dropout=0.5, emb_dropout=0.25, emsize=50, epochs=30, log_interval=100, lr=4, optim='SGD', save='model.pt', seed=1111, weight=10.0, word_kernel_size=3, word_layers=3, word_nhid=300)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "print(args)\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Charset(Index):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        for char in string.printable[0:-6]:#所有的字母加符号\n",
    "            self.add(char)\n",
    "        self.add(\"<pad>\")\n",
    "        self.add(\"<unk>\")\n",
    "\n",
    "    @staticmethod\n",
    "    def type(char):\n",
    "        if char in string.digits:\n",
    "            return \"Digits\"\n",
    "        if char in string.ascii_lowercase:\n",
    "            return \"Lower Case\"\n",
    "        if char in string.ascii_uppercase:\n",
    "            return \"Upper Case\"\n",
    "        if char in string.punctuation:\n",
    "            return \"Punctuation\"\n",
    "        return \"Other\"\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, str) and key not in self.key2idx:\n",
    "            return self.key2idx[\"<unk>\"]\n",
    "        return super().__getitem__(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index(object):\n",
    "    def __init__(self):\n",
    "        self.key2idx = {}\n",
    "        self.idx2key = []\n",
    "\n",
    "    def add(self, key):\n",
    "        if key not in self.key2idx:\n",
    "            self.key2idx[key] = len(self.idx2key)\n",
    "            self.idx2key.append(key)\n",
    "        return self.key2idx[key]\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, str):\n",
    "            return self.key2idx[key]\n",
    "        if isinstance(key, int):\n",
    "            return self.idx2key[key]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2key)\n",
    "\n",
    "    def save(self, f):\n",
    "        with open(f, 'wt', encoding='utf-8') as fout:\n",
    "            for index, key in enumerate(self.idx2key):\n",
    "                fout.write(key + '\\t' + str(index) + '\\n')\n",
    "\n",
    "    def load(self, f):\n",
    "        with open(f, 'rt', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                key = line.split()[0]\n",
    "                self.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(Index):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add(\"<pad>\")\n",
    "        self.add(\"<unk>\")\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, str) and key not in self.key2idx:\n",
    "            return self.key2idx[\"<unk>\"]\n",
    "        return super().__getitem__(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charset = Charset()\n",
    "vocab = Vocabulary()\n",
    "vocab.load(\"data/NYT_CoType/vocab.txt\")\n",
    "relation_labels = Index()\n",
    "entity_labels = Index()\n",
    "tag_set = Index()\n",
    "tag_set.add(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 70\n",
    "MAX_TOKEN_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open('data/NYT_CoType/test.json', 'rt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sentId\": 33, \"articleId\": \"2\", \"relationMentions\": [{\"em1Text\": \"Tim Pawlenty\", \"em2Text\": \"Minnesota\", \"label\": \"/people/person/place_lived\"}, {\"em1Text\": \"Minnesota\", \"em2Text\": \"Tim Pawlenty\", \"label\": \"None\"}], \"entityMentions\": [{\"start\": 0, \"text\": \"Tim Pawlenty\", \"label\": \"PERSON\"}, {\"start\": 1, \"text\": \"Minnesota\", \"label\": \"LOCATION\"}], \"sentText\": \"Gov. Tim Pawlenty of Minnesota ordered the state health department this month to monitor day-to-day operations at the Minneapolis Veterans Home after state inspectors found that three men had died there in the previous month because of neglect or medical errors .\\\\r\\\\n\"}\\n'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = fin.readline()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare_data_set\n",
    "num_overlap = 0\n",
    "overlap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentId': 33,\n",
       " 'articleId': '2',\n",
       " 'relationMentions': [{'em1Text': 'Tim Pawlenty',\n",
       "   'em2Text': 'Minnesota',\n",
       "   'label': '/people/person/place_lived'},\n",
       "  {'em1Text': 'Minnesota', 'em2Text': 'Tim Pawlenty', 'label': 'None'}],\n",
       " 'entityMentions': [{'start': 0, 'text': 'Tim Pawlenty', 'label': 'PERSON'},\n",
       "  {'start': 1, 'text': 'Minnesota', 'label': 'LOCATION'}],\n",
       " 'sentText': 'Gov. Tim Pawlenty of Minnesota ordered the state health department this month to monitor day-to-day operations at the Minneapolis Veterans Home after state inspectors found that three men had died there in the previous month because of neglect or medical errors .\\r\\n'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = json.loads(line)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tag_set(tag_set, relation_label):\n",
    "    if relation_label == \"None\":\n",
    "        return\n",
    "    for pos in \"BIES\":\n",
    "        for role in \"12\":\n",
    "            tag_set.add(\"-\".join([pos, relation_label, role]))#pos-relation_label-role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation_mention in sentence[\"relationMentions\"]:\n",
    "    relation_labels.add(relation_mention[\"label\"])\n",
    "    make_tag_set(tag_set, relation_mention[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/people/person/place_lived', 'None']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_labels.idx2key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity_mention in sentence[\"entityMentions\"]:\n",
    "    entity_labels.add(entity_mention[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PERSON', 'LOCATION']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_labels.idx2key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gov.',\n",
       " 'Tim',\n",
       " 'Pawlenty',\n",
       " 'of',\n",
       " 'Minnesota',\n",
       " 'ordered',\n",
       " 'the',\n",
       " 'state',\n",
       " 'health',\n",
       " 'department',\n",
       " 'this',\n",
       " 'month',\n",
       " 'to',\n",
       " 'monitor',\n",
       " 'day-to-day',\n",
       " 'operations',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Minneapolis',\n",
       " 'Veterans',\n",
       " 'Home',\n",
       " 'after',\n",
       " 'state',\n",
       " 'inspectors',\n",
       " 'found',\n",
       " 'that',\n",
       " 'three',\n",
       " 'men',\n",
       " 'had',\n",
       " 'died',\n",
       " 'there',\n",
       " 'in',\n",
       " 'the',\n",
       " 'previous',\n",
       " 'month',\n",
       " 'because',\n",
       " 'of',\n",
       " 'neglect',\n",
       " 'or',\n",
       " 'medical',\n",
       " 'errors',\n",
       " '.']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_text = sentence[\"sentText\"].strip().strip('\"').split()\n",
    "sentence_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_sent = len(sentence_text)\n",
    "length_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gov.',\n",
       " 'tim',\n",
       " 'pawlenty',\n",
       " 'of',\n",
       " 'minnesota',\n",
       " 'ordered',\n",
       " 'the',\n",
       " 'state',\n",
       " 'health',\n",
       " 'department',\n",
       " 'this',\n",
       " 'month',\n",
       " 'to',\n",
       " 'monitor',\n",
       " 'day-to-day',\n",
       " 'operations',\n",
       " 'at',\n",
       " 'the',\n",
       " 'minneapolis',\n",
       " 'veterans',\n",
       " 'home',\n",
       " 'after',\n",
       " 'state',\n",
       " 'inspectors',\n",
       " 'found',\n",
       " 'that',\n",
       " 'three',\n",
       " 'men',\n",
       " 'had',\n",
       " 'died',\n",
       " 'there',\n",
       " 'in',\n",
       " 'the',\n",
       " 'previous',\n",
       " 'month',\n",
       " 'because',\n",
       " 'of',\n",
       " 'neglect',\n",
       " 'or',\n",
       " 'medical',\n",
       " 'errors',\n",
       " '.']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_sentence_text = [token.lower() for token in sentence_text]\n",
    "lower_sentence_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " ',': 2,\n",
       " 'the': 3,\n",
       " 'and': 4,\n",
       " 'of': 5,\n",
       " '.': 6,\n",
       " 'in': 7,\n",
       " 'a': 8,\n",
       " 'to': 9,\n",
       " \"''\": 10,\n",
       " \"'s\": 11,\n",
       " 'for': 12,\n",
       " 'that': 13,\n",
       " 'on': 14,\n",
       " 'at': 15,\n",
       " 'with': 16,\n",
       " 'is': 17,\n",
       " 'by': 18,\n",
       " 'from': 19,\n",
       " 'new': 20,\n",
       " 'was': 21,\n",
       " 'as': 22,\n",
       " 'his': 23,\n",
       " 'he': 24,\n",
       " 'who': 25,\n",
       " 'said': 26,\n",
       " ';': 27,\n",
       " '-rrb-': 28,\n",
       " '-lrb-': 29,\n",
       " 'an': 30,\n",
       " '--': 31,\n",
       " 'has': 32,\n",
       " 'it': 33,\n",
       " 'mr.': 34,\n",
       " 'york': 35,\n",
       " 'have': 36,\n",
       " 'had': 37,\n",
       " 'be': 38,\n",
       " 'united': 39,\n",
       " 'but': 40,\n",
       " ':': 41,\n",
       " 'are': 42,\n",
       " 'its': 43,\n",
       " 'not': 44,\n",
       " 'which': 45,\n",
       " 'states': 46,\n",
       " 'about': 47,\n",
       " 'this': 48,\n",
       " 'her': 49,\n",
       " 'one': 50,\n",
       " 'will': 51,\n",
       " 'after': 52,\n",
       " 'their': 53,\n",
       " 'president': 54,\n",
       " 'when': 55,\n",
       " 'like': 56,\n",
       " 'last': 57,\n",
       " 'two': 58,\n",
       " 'were': 59,\n",
       " 'would': 60,\n",
       " 'they': 61,\n",
       " 'city': 62,\n",
       " 'or': 63,\n",
       " 'been': 64,\n",
       " 'more': 65,\n",
       " '$': 66,\n",
       " 'years': 67,\n",
       " 'first': 68,\n",
       " 'other': 69,\n",
       " 'she': 70,\n",
       " 'up': 71,\n",
       " 'also': 72,\n",
       " 'where': 73,\n",
       " 'iraq': 74,\n",
       " 'university': 75,\n",
       " 'than': 76,\n",
       " 'john': 77,\n",
       " 'i': 78,\n",
       " 'former': 79,\n",
       " 'year': 80,\n",
       " 'state': 81,\n",
       " 'out': 82,\n",
       " 'bush': 83,\n",
       " 'into': 84,\n",
       " 'over': 85,\n",
       " 'american': 86,\n",
       " \"'\": 87,\n",
       " 'there': 88,\n",
       " 'most': 89,\n",
       " 'all': 90,\n",
       " 'china': 91,\n",
       " 'some': 92,\n",
       " 'house': 93,\n",
       " 'washington': 94,\n",
       " 'world': 95,\n",
       " 'company': 96,\n",
       " 'three': 97,\n",
       " 'now': 98,\n",
       " 'time': 99,\n",
       " 'including': 100,\n",
       " 'brooklyn': 101,\n",
       " 'manhattan': 102,\n",
       " 'him': 103,\n",
       " 'we': 104,\n",
       " 'if': 105,\n",
       " 'north': 106,\n",
       " 'against': 107,\n",
       " 'before': 108,\n",
       " 'east': 109,\n",
       " 'israel': 110,\n",
       " 'people': 111,\n",
       " 'what': 112,\n",
       " 'home': 113,\n",
       " 'west': 114,\n",
       " 'long': 115,\n",
       " 'could': 116,\n",
       " 'school': 117,\n",
       " 'between': 118,\n",
       " 'south': 119,\n",
       " 'david': 120,\n",
       " 'made': 121,\n",
       " 'only': 122,\n",
       " 'island': 123,\n",
       " 'through': 124,\n",
       " 'group': 125,\n",
       " 'because': 126,\n",
       " 'center': 127,\n",
       " 'while': 128,\n",
       " 'chief': 129,\n",
       " 'republican': 130,\n",
       " 'many': 131,\n",
       " 'so': 132,\n",
       " 'war': 133,\n",
       " 'jersey': 134,\n",
       " 'america': 135,\n",
       " 'national': 136,\n",
       " 'iran': 137,\n",
       " 'california': 138,\n",
       " 'you': 139,\n",
       " 'wife': 140,\n",
       " 'michael': 141,\n",
       " 'million': 142,\n",
       " 'europe': 143,\n",
       " 'may': 144,\n",
       " 'county': 145,\n",
       " 'senator': 146,\n",
       " 'week': 147,\n",
       " 'ms.': 148,\n",
       " 'director': 149,\n",
       " 'just': 150,\n",
       " 'executive': 151,\n",
       " 'no': 152,\n",
       " 'since': 153,\n",
       " 'then': 154,\n",
       " 'them': 155,\n",
       " 'general': 156,\n",
       " 'even': 157,\n",
       " 'yesterday': 158,\n",
       " 'did': 159,\n",
       " 'street': 160,\n",
       " 'officials': 161,\n",
       " 'can': 162,\n",
       " 'part': 163,\n",
       " \"n't\": 164,\n",
       " 'among': 165,\n",
       " 'san': 166,\n",
       " 'government': 167,\n",
       " 'four': 168,\n",
       " 'minister': 169,\n",
       " 'team': 170,\n",
       " 'during': 171,\n",
       " 'father': 172,\n",
       " 'london': 173,\n",
       " 'both': 174,\n",
       " 'well': 175,\n",
       " 'back': 176,\n",
       " 'robert': 177,\n",
       " 'son': 178,\n",
       " 'los': 179,\n",
       " 'france': 180,\n",
       " 'country': 181,\n",
       " 'day': 182,\n",
       " 'international': 183,\n",
       " 'james': 184,\n",
       " 'administration': 185,\n",
       " 'percent': 186,\n",
       " 'family': 187,\n",
       " 'angeles': 188,\n",
       " 'work': 189,\n",
       " 'nations': 190,\n",
       " 'do': 191,\n",
       " 'next': 192,\n",
       " 'white': 193,\n",
       " 'sunday': 194,\n",
       " 'germany': 195,\n",
       " 'off': 196,\n",
       " 'another': 197,\n",
       " 'whose': 198,\n",
       " 'george': 199,\n",
       " 'bill': 200,\n",
       " 'under': 201,\n",
       " 'queens': 202,\n",
       " 'russia': 203,\n",
       " 'those': 204,\n",
       " 'much': 205,\n",
       " 'way': 206,\n",
       " 'japan': 207,\n",
       " 'college': 208,\n",
       " 'ago': 209,\n",
       " 'called': 210,\n",
       " 'here': 211,\n",
       " 'senate': 212,\n",
       " 'news': 213,\n",
       " 'game': 214,\n",
       " 'political': 215,\n",
       " 'left': 216,\n",
       " 'art': 217,\n",
       " 'night': 218,\n",
       " 'public': 219,\n",
       " 'being': 220,\n",
       " 'children': 221,\n",
       " 'still': 222,\n",
       " 'chairman': 223,\n",
       " 'based': 224,\n",
       " 'bank': 225,\n",
       " 'late': 226,\n",
       " 'paul': 227,\n",
       " 'month': 228,\n",
       " 'park': 229,\n",
       " 'richard': 230,\n",
       " 'florida': 231,\n",
       " '&': 232,\n",
       " 'make': 233,\n",
       " '10': 234,\n",
       " 'law': 235,\n",
       " 'mother': 236,\n",
       " 'program': 237,\n",
       " 'music': 238,\n",
       " 'security': 239,\n",
       " 'daughter': 240,\n",
       " 'st.': 241,\n",
       " 'chicago': 242,\n",
       " 'second': 243,\n",
       " 'five': 244,\n",
       " 'texas': 245,\n",
       " 'office': 246,\n",
       " 'show': 247,\n",
       " 'boston': 248,\n",
       " 'thursday': 249,\n",
       " 'j.': 250,\n",
       " 'our': 251,\n",
       " 'museum': 252,\n",
       " 'several': 253,\n",
       " 'business': 254,\n",
       " 'wednesday': 255,\n",
       " 'times': 256,\n",
       " 'how': 257,\n",
       " 'play': 258,\n",
       " 'near': 259,\n",
       " 'dr.': 260,\n",
       " 'union': 261,\n",
       " 'tuesday': 262,\n",
       " 'military': 263,\n",
       " 'italy': 264,\n",
       " 'season': 265,\n",
       " 'born': 266,\n",
       " 'middle': 267,\n",
       " 'thomas': 268,\n",
       " 'prime': 269,\n",
       " 'friday': 270,\n",
       " 'recent': 271,\n",
       " 'representative': 272,\n",
       " '`': 273,\n",
       " 'down': 274,\n",
       " 'leader': 275,\n",
       " 'own': 276,\n",
       " 'india': 277,\n",
       " 'around': 278,\n",
       " 'n.y.': 279,\n",
       " 'young': 280,\n",
       " 'european': 281,\n",
       " 'court': 282,\n",
       " 'ohio': 283,\n",
       " 'nuclear': 284,\n",
       " 'high': 285,\n",
       " 'early': 286,\n",
       " 'any': 287,\n",
       " 'monday': 288,\n",
       " 'survived': 289,\n",
       " 'according': 290,\n",
       " 'korea': 291,\n",
       " 'connecticut': 292,\n",
       " 'say': 293,\n",
       " 'take': 294,\n",
       " 'life': 295,\n",
       " 'p.m.': 296,\n",
       " 'place': 297,\n",
       " 'mexico': 298,\n",
       " 'along': 299,\n",
       " 'died': 300,\n",
       " 'district': 301,\n",
       " 'professor': 302,\n",
       " 'major': 303,\n",
       " 'secretary': 304,\n",
       " 'end': 305,\n",
       " 'england': 306,\n",
       " 'came': 307,\n",
       " 'husband': 308,\n",
       " 'democratic': 309,\n",
       " 'coach': 310,\n",
       " 'man': 311,\n",
       " 'federal': 312,\n",
       " 'congress': 313,\n",
       " 'set': 314,\n",
       " 'mark': 315,\n",
       " '1': 316,\n",
       " 'peter': 317,\n",
       " 'party': 318,\n",
       " 'film': 319,\n",
       " 'johnson': 320,\n",
       " 'britain': 321,\n",
       " 'top': 322,\n",
       " 'william': 323,\n",
       " 'few': 324,\n",
       " 'countries': 325,\n",
       " 'took': 326,\n",
       " 'great': 327,\n",
       " 'right': 328,\n",
       " 'police': 329,\n",
       " 'days': 330,\n",
       " 'played': 331,\n",
       " 'town': 332,\n",
       " 'recently': 333,\n",
       " 'best': 334,\n",
       " 'members': 335,\n",
       " 'known': 336,\n",
       " 'brown': 337,\n",
       " 'avenue': 338,\n",
       " 'my': 339,\n",
       " 'saturday': 340,\n",
       " 'told': 341,\n",
       " 'same': 342,\n",
       " 'later': 343,\n",
       " 'paris': 344,\n",
       " 'won': 345,\n",
       " 'found': 346,\n",
       " 'get': 347,\n",
       " 'case': 348,\n",
       " 'companies': 349,\n",
       " 'baghdad': 350,\n",
       " 'big': 351,\n",
       " 'run': 352,\n",
       " 'should': 353,\n",
       " 'grandchildren': 354,\n",
       " 'began': 355,\n",
       " 'africa': 356,\n",
       " 'led': 357,\n",
       " 'article': 358,\n",
       " 'democrat': 359,\n",
       " 'philadelphia': 360,\n",
       " 'series': 361,\n",
       " 'beach': 362,\n",
       " 'committee': 363,\n",
       " 'foreign': 364,\n",
       " 'today': 365,\n",
       " 'service': 366,\n",
       " 'far': 367,\n",
       " 'become': 368,\n",
       " 'tom': 369,\n",
       " 'meeting': 370,\n",
       " 'brother': 371,\n",
       " 'francisco': 372,\n",
       " 'central': 373,\n",
       " 'include': 374,\n",
       " 'support': 375,\n",
       " 'senior': 376,\n",
       " 'though': 377,\n",
       " 'southern': 378,\n",
       " 'others': 379,\n",
       " 'little': 380,\n",
       " 'league': 381,\n",
       " 'might': 382,\n",
       " 'manager': 383,\n",
       " 'across': 384,\n",
       " '2005': 385,\n",
       " 'moved': 386,\n",
       " 'charles': 387,\n",
       " 'miles': 388,\n",
       " 'book': 389,\n",
       " 'campaign': 390,\n",
       " 'power': 391,\n",
       " 'trade': 392,\n",
       " 'leaders': 393,\n",
       " 'clinton': 394,\n",
       " 'department': 395,\n",
       " '2': 396,\n",
       " 'history': 397,\n",
       " 'six': 398,\n",
       " 'asia': 399,\n",
       " 'deal': 400,\n",
       " 'virginia': 401,\n",
       " 'river': 402,\n",
       " 'area': 403,\n",
       " 'side': 404,\n",
       " 'go': 405,\n",
       " 'oil': 406,\n",
       " 'once': 407,\n",
       " 'attorney': 408,\n",
       " '20': 409,\n",
       " 'months': 410,\n",
       " 'small': 411,\n",
       " 'lebanon': 412,\n",
       " 'help': 413,\n",
       " '2004': 414,\n",
       " 'used': 415,\n",
       " 'canada': 416,\n",
       " 'editor': 417,\n",
       " 'billion': 418,\n",
       " 'third': 419,\n",
       " 'until': 420,\n",
       " 'went': 421,\n",
       " 'open': 422,\n",
       " 'held': 423,\n",
       " 'june': 424,\n",
       " 'british': 425,\n",
       " 'became': 426,\n",
       " 'men': 427,\n",
       " '11': 428,\n",
       " 'past': 429,\n",
       " 'very': 430,\n",
       " 'n.j.': 431,\n",
       " 'come': 432,\n",
       " 'reported': 433,\n",
       " 'such': 434,\n",
       " '2006': 435,\n",
       " 'old': 436,\n",
       " 'these': 437,\n",
       " 'name': 438,\n",
       " 'vice': 439,\n",
       " 'july': 440,\n",
       " 'theater': 441,\n",
       " 'good': 442,\n",
       " '2003': 443,\n",
       " 'r.': 444,\n",
       " 'least': 445,\n",
       " 'beloved': 446,\n",
       " 'going': 447,\n",
       " 'worked': 448,\n",
       " '30': 449,\n",
       " 'does': 450,\n",
       " 'agency': 451,\n",
       " 'says': 452,\n",
       " 'plan': 453,\n",
       " 'conference': 454,\n",
       " 'works': 455,\n",
       " 'williams': 456,\n",
       " 'announced': 457,\n",
       " 'firm': 458,\n",
       " 'mike': 459,\n",
       " 'each': 460,\n",
       " 'received': 461,\n",
       " 'calif.': 462,\n",
       " 'syria': 463,\n",
       " 'region': 464,\n",
       " 'afghanistan': 465,\n",
       " 'capital': 466,\n",
       " 'named': 467,\n",
       " 'no.': 468,\n",
       " 'head': 469,\n",
       " 'put': 470,\n",
       " 'orleans': 471,\n",
       " 'outside': 472,\n",
       " 'governor': 473,\n",
       " 'television': 474,\n",
       " 'money': 475,\n",
       " 'a.': 476,\n",
       " 'martin': 477,\n",
       " 'mayor': 478,\n",
       " 'building': 479,\n",
       " 'already': 480,\n",
       " 'games': 481,\n",
       " 'march': 482,\n",
       " 'players': 483,\n",
       " 'black': 484,\n",
       " 'church': 485,\n",
       " 'houston': 486,\n",
       " 'red': 487,\n",
       " 'market': 488,\n",
       " 'away': 489,\n",
       " 'loving': 490,\n",
       " 'm.': 491,\n",
       " 'point': 492,\n",
       " 'women': 493,\n",
       " 'scott': 494,\n",
       " 'less': 495,\n",
       " 'without': 496,\n",
       " 'includes': 497,\n",
       " 'lives': 498,\n",
       " 'real': 499,\n",
       " 'use': 500,\n",
       " 'jr.': 501,\n",
       " 'victory': 502,\n",
       " 'smith': 503,\n",
       " 'joseph': 504,\n",
       " '15': 505,\n",
       " 'research': 506,\n",
       " 'never': 507,\n",
       " 'plans': 508,\n",
       " 'largest': 509,\n",
       " 'hill': 510,\n",
       " 'massachusetts': 511,\n",
       " 'sister': 512,\n",
       " 'working': 513,\n",
       " 'see': 514,\n",
       " 'carolina': 515,\n",
       " 'columbia': 516,\n",
       " 'council': 517,\n",
       " 'summer': 518,\n",
       " '8': 519,\n",
       " 'directed': 520,\n",
       " 'production': 521,\n",
       " 'too': 522,\n",
       " 'bay': 523,\n",
       " 'me': 524,\n",
       " 'lost': 525,\n",
       " 'member': 526,\n",
       " 'northern': 527,\n",
       " '3': 528,\n",
       " 'report': 529,\n",
       " 'policy': 530,\n",
       " 'whether': 531,\n",
       " 'role': 532,\n",
       " 'close': 533,\n",
       " 'behind': 534,\n",
       " 'visit': 535,\n",
       " 'de': 536,\n",
       " 'bob': 537,\n",
       " 'bronx': 538,\n",
       " 'institute': 539,\n",
       " 'board': 540,\n",
       " 'met': 541,\n",
       " 'move': 542,\n",
       " 'nearly': 543,\n",
       " 'lead': 544,\n",
       " 'included': 545,\n",
       " 'economic': 546,\n",
       " 'weeks': 547,\n",
       " 'official': 548,\n",
       " 'village': 549,\n",
       " 'force': 550,\n",
       " 'gaza': 551,\n",
       " 'line': 552,\n",
       " 'asked': 553,\n",
       " 'death': 554,\n",
       " 'e.': 555,\n",
       " 'd.': 556,\n",
       " 'local': 557,\n",
       " 'jack': 558,\n",
       " 'trying': 559,\n",
       " 'killed': 560,\n",
       " 'married': 561,\n",
       " 'making': 562,\n",
       " 'hall': 563,\n",
       " '?': 564,\n",
       " 'pennsylvania': 565,\n",
       " 'democrats': 566,\n",
       " 'cities': 567,\n",
       " 'half': 568,\n",
       " 'miami': 569,\n",
       " 'every': 570,\n",
       " 'lee': 571,\n",
       " 'atlanta': 572,\n",
       " 'number': 573,\n",
       " 'large': 574,\n",
       " 'energy': 575,\n",
       " 'devoted': 576,\n",
       " 'development': 577,\n",
       " 'palestinian': 578,\n",
       " 'frank': 579,\n",
       " '12': 580,\n",
       " 'expected': 581,\n",
       " 'australia': 582,\n",
       " '2002': 583,\n",
       " 'pakistan': 584,\n",
       " 'steve': 585,\n",
       " 'april': 586,\n",
       " 'w.': 587,\n",
       " 'minutes': 588,\n",
       " 'earlier': 589,\n",
       " 'army': 590,\n",
       " 'press': 591,\n",
       " 'think': 592,\n",
       " 'chinese': 593,\n",
       " 'rights': 594,\n",
       " 'club': 595,\n",
       " 'private': 596,\n",
       " 'final': 597,\n",
       " '5': 598,\n",
       " 'interview': 599,\n",
       " 'western': 600,\n",
       " 'himself': 601,\n",
       " 'race': 602,\n",
       " 'miller': 603,\n",
       " 'start': 604,\n",
       " 'story': 605,\n",
       " 'helped': 606,\n",
       " 'spain': 607,\n",
       " 'job': 608,\n",
       " 'jackson': 609,\n",
       " 'louis': 610,\n",
       " 'running': 611,\n",
       " 'daniel': 612,\n",
       " 'spent': 613,\n",
       " 'troops': 614,\n",
       " 'star': 615,\n",
       " 'field': 616,\n",
       " '6': 617,\n",
       " 'almost': 618,\n",
       " 'leading': 619,\n",
       " 'sent': 620,\n",
       " 'friends': 621,\n",
       " 'joe': 622,\n",
       " 'community': 623,\n",
       " '%': 624,\n",
       " 'tour': 625,\n",
       " 'health': 626,\n",
       " 'live': 627,\n",
       " 'coast': 628,\n",
       " 'andrew': 629,\n",
       " 'effort': 630,\n",
       " 'having': 631,\n",
       " '25': 632,\n",
       " 'project': 633,\n",
       " 'financial': 634,\n",
       " 'saying': 635,\n",
       " 'services': 636,\n",
       " 'us': 637,\n",
       " 'arts': 638,\n",
       " 'republicans': 639,\n",
       " 'stephen': 640,\n",
       " 'border': 641,\n",
       " 'defense': 642,\n",
       " 'road': 643,\n",
       " 'free': 644,\n",
       " 'air': 645,\n",
       " 'talks': 646,\n",
       " 'mary': 647,\n",
       " '4': 648,\n",
       " 'hospital': 649,\n",
       " 'wrote': 650,\n",
       " 'friend': 651,\n",
       " 'nation': 652,\n",
       " 'students': 653,\n",
       " 'trip': 654,\n",
       " 'site': 655,\n",
       " 'arizona': 656,\n",
       " 'division': 657,\n",
       " 'jim': 658,\n",
       " 'love': 659,\n",
       " 'brian': 660,\n",
       " 'l.': 661,\n",
       " 'hussein': 662,\n",
       " 'grew': 663,\n",
       " 'officer': 664,\n",
       " 'often': 665,\n",
       " 'fort': 666,\n",
       " 'gave': 667,\n",
       " 'career': 668,\n",
       " 'israeli': 669,\n",
       " 'gov.': 670,\n",
       " 'beijing': 671,\n",
       " 'lived': 672,\n",
       " 'although': 673,\n",
       " 'woman': 674,\n",
       " 'tony': 675,\n",
       " 'return': 676,\n",
       " '9': 677,\n",
       " 'toward': 678,\n",
       " 'rice': 679,\n",
       " 'medical': 680,\n",
       " 'started': 681,\n",
       " 'al': 682,\n",
       " 'decision': 683,\n",
       " 'seven': 684,\n",
       " 'sept.': 685,\n",
       " 'c.': 686,\n",
       " 'better': 687,\n",
       " 'given': 688,\n",
       " 'harvard': 689,\n",
       " '7': 690,\n",
       " 'lake': 691,\n",
       " 'points': 692,\n",
       " 'attacks': 693,\n",
       " 'control': 694,\n",
       " 'howard': 695,\n",
       " 'taken': 696,\n",
       " 'whom': 697,\n",
       " 'detroit': 698,\n",
       " 'living': 699,\n",
       " 'yankees': 700,\n",
       " 'give': 701,\n",
       " 'yet': 702,\n",
       " 'again': 703,\n",
       " 'want': 704,\n",
       " 'playing': 705,\n",
       " '100': 706,\n",
       " 'judge': 707,\n",
       " 'intelligence': 708,\n",
       " 'eastern': 709,\n",
       " 'h.': 710,\n",
       " 'chris': 711,\n",
       " 'jones': 712,\n",
       " 'hotel': 713,\n",
       " 'susan': 714,\n",
       " 'media': 715,\n",
       " 'released': 716,\n",
       " 'hit': 717,\n",
       " 'written': 718,\n",
       " 'taking': 719,\n",
       " 'seattle': 720,\n",
       " 'westchester': 721,\n",
       " 'opened': 722,\n",
       " 'forces': 723,\n",
       " 'example': 724,\n",
       " 'elizabeth': 725,\n",
       " 'tomorrow': 726,\n",
       " 'louisiana': 727,\n",
       " 'got': 728,\n",
       " \"'re\": 729,\n",
       " 'grandfather': 730,\n",
       " 's.': 731,\n",
       " 'organization': 732,\n",
       " 'agreement': 733,\n",
       " 'call': 734,\n",
       " 'lawyer': 735,\n",
       " 'places': 736,\n",
       " 'fall': 737,\n",
       " 'partner': 738,\n",
       " 'efforts': 739,\n",
       " 'record': 740,\n",
       " 'face': 741,\n",
       " 'spokesman': 742,\n",
       " 'important': 743,\n",
       " 'enough': 744,\n",
       " 'built': 745,\n",
       " '2000': 746,\n",
       " 'green': 747,\n",
       " 'know': 748,\n",
       " 'nbc': 749,\n",
       " 'davis': 750,\n",
       " 'christopher': 751,\n",
       " 'industry': 752,\n",
       " 'system': 753,\n",
       " 'author': 754,\n",
       " 'warner': 755,\n",
       " 'edward': 756,\n",
       " 'graduated': 757,\n",
       " 'residents': 758,\n",
       " 'ford': 759,\n",
       " 'commission': 760,\n",
       " 'henry': 761,\n",
       " 'player': 762,\n",
       " 'agreed': 763,\n",
       " 'jason': 764,\n",
       " 'look': 765,\n",
       " '50': 766,\n",
       " 'turned': 767,\n",
       " 'correction': 768,\n",
       " 'find': 769,\n",
       " '18': 770,\n",
       " 'hours': 771,\n",
       " 'current': 772,\n",
       " '2001': 773,\n",
       " 'owner': 774,\n",
       " 'artists': 775,\n",
       " 'hudson': 776,\n",
       " 'king': 777,\n",
       " 'together': 778,\n",
       " 'grandmother': 779,\n",
       " 'jordan': 780,\n",
       " 'served': 781,\n",
       " 'joined': 782,\n",
       " 'cbs': 783,\n",
       " 'justice': 784,\n",
       " 'special': 785,\n",
       " 'iraqi': 786,\n",
       " 'issue': 787,\n",
       " 'relations': 788,\n",
       " 'majority': 789,\n",
       " 'b.': 790,\n",
       " 'room': 791,\n",
       " 'barbara': 792,\n",
       " 'starting': 793,\n",
       " 'degree': 794,\n",
       " 'your': 795,\n",
       " 'candidate': 796,\n",
       " '16': 797,\n",
       " 'sons': 798,\n",
       " 'signed': 799,\n",
       " '14': 800,\n",
       " 'operations': 801,\n",
       " 'dallas': 802,\n",
       " 'parts': 803,\n",
       " 'retired': 804,\n",
       " 'corporation': 805,\n",
       " 'estate': 806,\n",
       " 'meet': 807,\n",
       " 'offer': 808,\n",
       " 'election': 809,\n",
       " 'brought': 810,\n",
       " 'saddam': 811,\n",
       " 'seen': 812,\n",
       " 'change': 813,\n",
       " 'schools': 814,\n",
       " 'french': 815,\n",
       " 'study': 816,\n",
       " 'main': 817,\n",
       " 'steven': 818,\n",
       " 'cup': 819,\n",
       " 'need': 820,\n",
       " 'ny': 821,\n",
       " 'civil': 822,\n",
       " 'eric': 823,\n",
       " '\\\\*': 824,\n",
       " 'valley': 825,\n",
       " 'movie': 826,\n",
       " 'sports': 827,\n",
       " 'growing': 828,\n",
       " 'list': 829,\n",
       " 'fox': 830,\n",
       " 'airport': 831,\n",
       " 'morning': 832,\n",
       " 'technology': 833,\n",
       " 'festival': 834,\n",
       " 'vote': 835,\n",
       " 'egypt': 836,\n",
       " 'lot': 837,\n",
       " 'brazil': 838,\n",
       " 'groups': 839,\n",
       " 'sales': 840,\n",
       " 'newark': 841,\n",
       " 'restaurant': 842,\n",
       " 'mrs.': 843,\n",
       " 'taiwan': 844,\n",
       " 'possible': 845,\n",
       " 'teams': 846,\n",
       " '13': 847,\n",
       " 'jonathan': 848,\n",
       " 'network': 849,\n",
       " 'attack': 850,\n",
       " 'gas': 851,\n",
       " 'base': 852,\n",
       " 'page': 853,\n",
       " 'weekend': 854,\n",
       " 'georgia': 855,\n",
       " 'assistant': 856,\n",
       " 'kansas': 857,\n",
       " 'why': 858,\n",
       " 'kennedy': 859,\n",
       " 'americans': 860,\n",
       " 'peace': 861,\n",
       " 'stop': 862,\n",
       " 'parents': 863,\n",
       " 'win': 864,\n",
       " 'investigation': 865,\n",
       " 'pay': 866,\n",
       " 'kevin': 867,\n",
       " 'raised': 868,\n",
       " 'addition': 869,\n",
       " 'f.': 870,\n",
       " 'keep': 871,\n",
       " 'eight': 872,\n",
       " 'stars': 873,\n",
       " 'short': 874,\n",
       " 'wanted': 875,\n",
       " 'future': 876,\n",
       " 'especially': 877,\n",
       " 'within': 878,\n",
       " 'produced': 879,\n",
       " 'similar': 880,\n",
       " 'january': 881,\n",
       " 'jeff': 882,\n",
       " 'plays': 883,\n",
       " 'staff': 884,\n",
       " 'allen': 885,\n",
       " 'brothers': 886,\n",
       " 'football': 887,\n",
       " 'weapons': 888,\n",
       " 'social': 889,\n",
       " 'native': 890,\n",
       " 'age': 891,\n",
       " 'association': 892,\n",
       " 'michigan': 893,\n",
       " 'course': 894,\n",
       " 'global': 895,\n",
       " 'human': 896,\n",
       " 'sudan': 897,\n",
       " 'different': 898,\n",
       " 'something': 899,\n",
       " 'moving': 900,\n",
       " '17': 901,\n",
       " 'soon': 902,\n",
       " 'runs': 903,\n",
       " 'anthony': 904,\n",
       " 'travel': 905,\n",
       " 'ambassador': 906,\n",
       " 'ever': 907,\n",
       " 'moscow': 908,\n",
       " 'wilson': 909,\n",
       " 'fla.': 910,\n",
       " 'november': 911,\n",
       " 'mets': 912,\n",
       " 'car': 913,\n",
       " 'education': 914,\n",
       " 'strong': 915,\n",
       " 'despite': 916,\n",
       " 'statement': 917,\n",
       " 'port': 918,\n",
       " 'full': 919,\n",
       " 'areas': 920,\n",
       " 'u.s.': 921,\n",
       " 'turkey': 922,\n",
       " 'workers': 923,\n",
       " 'arab': 924,\n",
       " 'lincoln': 925,\n",
       " 'created': 926,\n",
       " 'sold': 927,\n",
       " 'management': 928,\n",
       " 'streets': 929,\n",
       " 'likely': 930,\n",
       " 'investment': 931,\n",
       " 'morgan': 932,\n",
       " 'coming': 933,\n",
       " 'writer': 934,\n",
       " '22': 935,\n",
       " 'heights': 936,\n",
       " 'alan': 937,\n",
       " 'perhaps': 938,\n",
       " 'mississippi': 939,\n",
       " 'clear': 940,\n",
       " 'tonight': 941,\n",
       " 'thousands': 942,\n",
       " '-': 943,\n",
       " 'larry': 944,\n",
       " 'scheduled': 945,\n",
       " 'rose': 946,\n",
       " 'food': 947,\n",
       " 'evening': 948,\n",
       " 'biggest': 949,\n",
       " 'owned': 950,\n",
       " '40': 951,\n",
       " 'books': 952,\n",
       " 'aid': 953,\n",
       " 'kind': 954,\n",
       " 'diego': 955,\n",
       " 'build': 956,\n",
       " 'neighborhood': 957,\n",
       " 'front': 958,\n",
       " 'ii': 959,\n",
       " 'misstated': 960,\n",
       " 'title': 961,\n",
       " 'mass.': 962,\n",
       " 'always': 963,\n",
       " 'land': 964,\n",
       " 'station': 965,\n",
       " 'spring': 966,\n",
       " 'matthew': 967,\n",
       " 'guard': 968,\n",
       " 'radio': 969,\n",
       " 'atlantic': 970,\n",
       " 'popular': 971,\n",
       " '60': 972,\n",
       " 'sharon': 973,\n",
       " 'student': 974,\n",
       " 'lower': 975,\n",
       " 'grand': 976,\n",
       " 'toronto': 977,\n",
       " '24': 978,\n",
       " 'particularly': 979,\n",
       " 'tennessee': 980,\n",
       " 'modern': 981,\n",
       " 'must': 982,\n",
       " 'kong': 983,\n",
       " 'collection': 984,\n",
       " 'charges': 985,\n",
       " 'calls': 986,\n",
       " 'space': 987,\n",
       " 'hong': 988,\n",
       " 'december': 989,\n",
       " 'position': 990,\n",
       " 'tax': 991,\n",
       " 'square': 992,\n",
       " 'a.m.': 993,\n",
       " 'taylor': 994,\n",
       " 'looking': 995,\n",
       " 'shot': 996,\n",
       " 'information': 997,\n",
       " 'band': 998,\n",
       " 'pittsburgh': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.key2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_idx):\n",
    "    return [to_idx[key] for key in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[670,\n",
       " 1158,\n",
       " 40526,\n",
       " 5,\n",
       " 1018,\n",
       " 2037,\n",
       " 3,\n",
       " 81,\n",
       " 626,\n",
       " 395,\n",
       " 48,\n",
       " 228,\n",
       " 9,\n",
       " 6048,\n",
       " 10868,\n",
       " 801,\n",
       " 15,\n",
       " 3,\n",
       " 2131,\n",
       " 2866,\n",
       " 113,\n",
       " 52,\n",
       " 81,\n",
       " 5755,\n",
       " 346,\n",
       " 13,\n",
       " 97,\n",
       " 427,\n",
       " 37,\n",
       " 300,\n",
       " 88,\n",
       " 7,\n",
       " 3,\n",
       " 1713,\n",
       " 228,\n",
       " 126,\n",
       " 5,\n",
       " 15086,\n",
       " 63,\n",
       " 680,\n",
       " 7733,\n",
       " 6]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_idx = prepare_sequence(lower_sentence_text, vocab)\n",
    "sentence_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_idx = []\n",
    "for token in sentence_text:\n",
    "    if len(token) <= MAX_TOKEN_LENGTH:\n",
    "        tokens_idx.append(prepare_sequence(token, charset) + [charset[\"<pad>\"]]*(MAX_TOKEN_LENGTH-len(token)))\n",
    "    else:\n",
    "        tokens_idx.append(prepare_sequence(token[0:13] + token[-7:], charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_idx = [tag_set[\"O\"]] * length_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.append((sentence_idx, tokens_idx, tags_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环结束，保存数据\n",
    "save(test, 'data/NYT_CoType/test.pk')\n",
    "relation_labels.save('data/NYT_CoType/relation_labels.txt')\n",
    "entity_labels.save('data/NYT_CoType/entity_labels.txt')\n",
    "tag_set.save(\"data/NYT_CoType/tag2id.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = Charset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.load(\"data/NYT_CoType/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " ',': 2,\n",
       " 'the': 3,\n",
       " 'and': 4,\n",
       " 'of': 5,\n",
       " '.': 6,\n",
       " 'in': 7,\n",
       " 'a': 8,\n",
       " 'to': 9,\n",
       " \"''\": 10,\n",
       " \"'s\": 11,\n",
       " 'for': 12,\n",
       " 'that': 13,\n",
       " 'on': 14,\n",
       " 'at': 15,\n",
       " 'with': 16,\n",
       " 'is': 17,\n",
       " 'by': 18,\n",
       " 'from': 19,\n",
       " 'new': 20,\n",
       " 'was': 21,\n",
       " 'as': 22,\n",
       " 'his': 23,\n",
       " 'he': 24,\n",
       " 'who': 25,\n",
       " 'said': 26,\n",
       " ';': 27,\n",
       " '-rrb-': 28,\n",
       " '-lrb-': 29,\n",
       " 'an': 30,\n",
       " '--': 31,\n",
       " 'has': 32,\n",
       " 'it': 33,\n",
       " 'mr.': 34,\n",
       " 'york': 35,\n",
       " 'have': 36,\n",
       " 'had': 37,\n",
       " 'be': 38,\n",
       " 'united': 39,\n",
       " 'but': 40,\n",
       " ':': 41,\n",
       " 'are': 42,\n",
       " 'its': 43,\n",
       " 'not': 44,\n",
       " 'which': 45,\n",
       " 'states': 46,\n",
       " 'about': 47,\n",
       " 'this': 48,\n",
       " 'her': 49,\n",
       " 'one': 50,\n",
       " 'will': 51,\n",
       " 'after': 52,\n",
       " 'their': 53,\n",
       " 'president': 54,\n",
       " 'when': 55,\n",
       " 'like': 56,\n",
       " 'last': 57,\n",
       " 'two': 58,\n",
       " 'were': 59,\n",
       " 'would': 60,\n",
       " 'they': 61,\n",
       " 'city': 62,\n",
       " 'or': 63,\n",
       " 'been': 64,\n",
       " 'more': 65,\n",
       " '$': 66,\n",
       " 'years': 67,\n",
       " 'first': 68,\n",
       " 'other': 69,\n",
       " 'she': 70,\n",
       " 'up': 71,\n",
       " 'also': 72,\n",
       " 'where': 73,\n",
       " 'iraq': 74,\n",
       " 'university': 75,\n",
       " 'than': 76,\n",
       " 'john': 77,\n",
       " 'i': 78,\n",
       " 'former': 79,\n",
       " 'year': 80,\n",
       " 'state': 81,\n",
       " 'out': 82,\n",
       " 'bush': 83,\n",
       " 'into': 84,\n",
       " 'over': 85,\n",
       " 'american': 86,\n",
       " \"'\": 87,\n",
       " 'there': 88,\n",
       " 'most': 89,\n",
       " 'all': 90,\n",
       " 'china': 91,\n",
       " 'some': 92,\n",
       " 'house': 93,\n",
       " 'washington': 94,\n",
       " 'world': 95,\n",
       " 'company': 96,\n",
       " 'three': 97,\n",
       " 'now': 98,\n",
       " 'time': 99,\n",
       " 'including': 100,\n",
       " 'brooklyn': 101,\n",
       " 'manhattan': 102,\n",
       " 'him': 103,\n",
       " 'we': 104,\n",
       " 'if': 105,\n",
       " 'north': 106,\n",
       " 'against': 107,\n",
       " 'before': 108,\n",
       " 'east': 109,\n",
       " 'israel': 110,\n",
       " 'people': 111,\n",
       " 'what': 112,\n",
       " 'home': 113,\n",
       " 'west': 114,\n",
       " 'long': 115,\n",
       " 'could': 116,\n",
       " 'school': 117,\n",
       " 'between': 118,\n",
       " 'south': 119,\n",
       " 'david': 120,\n",
       " 'made': 121,\n",
       " 'only': 122,\n",
       " 'island': 123,\n",
       " 'through': 124,\n",
       " 'group': 125,\n",
       " 'because': 126,\n",
       " 'center': 127,\n",
       " 'while': 128,\n",
       " 'chief': 129,\n",
       " 'republican': 130,\n",
       " 'many': 131,\n",
       " 'so': 132,\n",
       " 'war': 133,\n",
       " 'jersey': 134,\n",
       " 'america': 135,\n",
       " 'national': 136,\n",
       " 'iran': 137,\n",
       " 'california': 138,\n",
       " 'you': 139,\n",
       " 'wife': 140,\n",
       " 'michael': 141,\n",
       " 'million': 142,\n",
       " 'europe': 143,\n",
       " 'may': 144,\n",
       " 'county': 145,\n",
       " 'senator': 146,\n",
       " 'week': 147,\n",
       " 'ms.': 148,\n",
       " 'director': 149,\n",
       " 'just': 150,\n",
       " 'executive': 151,\n",
       " 'no': 152,\n",
       " 'since': 153,\n",
       " 'then': 154,\n",
       " 'them': 155,\n",
       " 'general': 156,\n",
       " 'even': 157,\n",
       " 'yesterday': 158,\n",
       " 'did': 159,\n",
       " 'street': 160,\n",
       " 'officials': 161,\n",
       " 'can': 162,\n",
       " 'part': 163,\n",
       " \"n't\": 164,\n",
       " 'among': 165,\n",
       " 'san': 166,\n",
       " 'government': 167,\n",
       " 'four': 168,\n",
       " 'minister': 169,\n",
       " 'team': 170,\n",
       " 'during': 171,\n",
       " 'father': 172,\n",
       " 'london': 173,\n",
       " 'both': 174,\n",
       " 'well': 175,\n",
       " 'back': 176,\n",
       " 'robert': 177,\n",
       " 'son': 178,\n",
       " 'los': 179,\n",
       " 'france': 180,\n",
       " 'country': 181,\n",
       " 'day': 182,\n",
       " 'international': 183,\n",
       " 'james': 184,\n",
       " 'administration': 185,\n",
       " 'percent': 186,\n",
       " 'family': 187,\n",
       " 'angeles': 188,\n",
       " 'work': 189,\n",
       " 'nations': 190,\n",
       " 'do': 191,\n",
       " 'next': 192,\n",
       " 'white': 193,\n",
       " 'sunday': 194,\n",
       " 'germany': 195,\n",
       " 'off': 196,\n",
       " 'another': 197,\n",
       " 'whose': 198,\n",
       " 'george': 199,\n",
       " 'bill': 200,\n",
       " 'under': 201,\n",
       " 'queens': 202,\n",
       " 'russia': 203,\n",
       " 'those': 204,\n",
       " 'much': 205,\n",
       " 'way': 206,\n",
       " 'japan': 207,\n",
       " 'college': 208,\n",
       " 'ago': 209,\n",
       " 'called': 210,\n",
       " 'here': 211,\n",
       " 'senate': 212,\n",
       " 'news': 213,\n",
       " 'game': 214,\n",
       " 'political': 215,\n",
       " 'left': 216,\n",
       " 'art': 217,\n",
       " 'night': 218,\n",
       " 'public': 219,\n",
       " 'being': 220,\n",
       " 'children': 221,\n",
       " 'still': 222,\n",
       " 'chairman': 223,\n",
       " 'based': 224,\n",
       " 'bank': 225,\n",
       " 'late': 226,\n",
       " 'paul': 227,\n",
       " 'month': 228,\n",
       " 'park': 229,\n",
       " 'richard': 230,\n",
       " 'florida': 231,\n",
       " '&': 232,\n",
       " 'make': 233,\n",
       " '10': 234,\n",
       " 'law': 235,\n",
       " 'mother': 236,\n",
       " 'program': 237,\n",
       " 'music': 238,\n",
       " 'security': 239,\n",
       " 'daughter': 240,\n",
       " 'st.': 241,\n",
       " 'chicago': 242,\n",
       " 'second': 243,\n",
       " 'five': 244,\n",
       " 'texas': 245,\n",
       " 'office': 246,\n",
       " 'show': 247,\n",
       " 'boston': 248,\n",
       " 'thursday': 249,\n",
       " 'j.': 250,\n",
       " 'our': 251,\n",
       " 'museum': 252,\n",
       " 'several': 253,\n",
       " 'business': 254,\n",
       " 'wednesday': 255,\n",
       " 'times': 256,\n",
       " 'how': 257,\n",
       " 'play': 258,\n",
       " 'near': 259,\n",
       " 'dr.': 260,\n",
       " 'union': 261,\n",
       " 'tuesday': 262,\n",
       " 'military': 263,\n",
       " 'italy': 264,\n",
       " 'season': 265,\n",
       " 'born': 266,\n",
       " 'middle': 267,\n",
       " 'thomas': 268,\n",
       " 'prime': 269,\n",
       " 'friday': 270,\n",
       " 'recent': 271,\n",
       " 'representative': 272,\n",
       " '`': 273,\n",
       " 'down': 274,\n",
       " 'leader': 275,\n",
       " 'own': 276,\n",
       " 'india': 277,\n",
       " 'around': 278,\n",
       " 'n.y.': 279,\n",
       " 'young': 280,\n",
       " 'european': 281,\n",
       " 'court': 282,\n",
       " 'ohio': 283,\n",
       " 'nuclear': 284,\n",
       " 'high': 285,\n",
       " 'early': 286,\n",
       " 'any': 287,\n",
       " 'monday': 288,\n",
       " 'survived': 289,\n",
       " 'according': 290,\n",
       " 'korea': 291,\n",
       " 'connecticut': 292,\n",
       " 'say': 293,\n",
       " 'take': 294,\n",
       " 'life': 295,\n",
       " 'p.m.': 296,\n",
       " 'place': 297,\n",
       " 'mexico': 298,\n",
       " 'along': 299,\n",
       " 'died': 300,\n",
       " 'district': 301,\n",
       " 'professor': 302,\n",
       " 'major': 303,\n",
       " 'secretary': 304,\n",
       " 'end': 305,\n",
       " 'england': 306,\n",
       " 'came': 307,\n",
       " 'husband': 308,\n",
       " 'democratic': 309,\n",
       " 'coach': 310,\n",
       " 'man': 311,\n",
       " 'federal': 312,\n",
       " 'congress': 313,\n",
       " 'set': 314,\n",
       " 'mark': 315,\n",
       " '1': 316,\n",
       " 'peter': 317,\n",
       " 'party': 318,\n",
       " 'film': 319,\n",
       " 'johnson': 320,\n",
       " 'britain': 321,\n",
       " 'top': 322,\n",
       " 'william': 323,\n",
       " 'few': 324,\n",
       " 'countries': 325,\n",
       " 'took': 326,\n",
       " 'great': 327,\n",
       " 'right': 328,\n",
       " 'police': 329,\n",
       " 'days': 330,\n",
       " 'played': 331,\n",
       " 'town': 332,\n",
       " 'recently': 333,\n",
       " 'best': 334,\n",
       " 'members': 335,\n",
       " 'known': 336,\n",
       " 'brown': 337,\n",
       " 'avenue': 338,\n",
       " 'my': 339,\n",
       " 'saturday': 340,\n",
       " 'told': 341,\n",
       " 'same': 342,\n",
       " 'later': 343,\n",
       " 'paris': 344,\n",
       " 'won': 345,\n",
       " 'found': 346,\n",
       " 'get': 347,\n",
       " 'case': 348,\n",
       " 'companies': 349,\n",
       " 'baghdad': 350,\n",
       " 'big': 351,\n",
       " 'run': 352,\n",
       " 'should': 353,\n",
       " 'grandchildren': 354,\n",
       " 'began': 355,\n",
       " 'africa': 356,\n",
       " 'led': 357,\n",
       " 'article': 358,\n",
       " 'democrat': 359,\n",
       " 'philadelphia': 360,\n",
       " 'series': 361,\n",
       " 'beach': 362,\n",
       " 'committee': 363,\n",
       " 'foreign': 364,\n",
       " 'today': 365,\n",
       " 'service': 366,\n",
       " 'far': 367,\n",
       " 'become': 368,\n",
       " 'tom': 369,\n",
       " 'meeting': 370,\n",
       " 'brother': 371,\n",
       " 'francisco': 372,\n",
       " 'central': 373,\n",
       " 'include': 374,\n",
       " 'support': 375,\n",
       " 'senior': 376,\n",
       " 'though': 377,\n",
       " 'southern': 378,\n",
       " 'others': 379,\n",
       " 'little': 380,\n",
       " 'league': 381,\n",
       " 'might': 382,\n",
       " 'manager': 383,\n",
       " 'across': 384,\n",
       " '2005': 385,\n",
       " 'moved': 386,\n",
       " 'charles': 387,\n",
       " 'miles': 388,\n",
       " 'book': 389,\n",
       " 'campaign': 390,\n",
       " 'power': 391,\n",
       " 'trade': 392,\n",
       " 'leaders': 393,\n",
       " 'clinton': 394,\n",
       " 'department': 395,\n",
       " '2': 396,\n",
       " 'history': 397,\n",
       " 'six': 398,\n",
       " 'asia': 399,\n",
       " 'deal': 400,\n",
       " 'virginia': 401,\n",
       " 'river': 402,\n",
       " 'area': 403,\n",
       " 'side': 404,\n",
       " 'go': 405,\n",
       " 'oil': 406,\n",
       " 'once': 407,\n",
       " 'attorney': 408,\n",
       " '20': 409,\n",
       " 'months': 410,\n",
       " 'small': 411,\n",
       " 'lebanon': 412,\n",
       " 'help': 413,\n",
       " '2004': 414,\n",
       " 'used': 415,\n",
       " 'canada': 416,\n",
       " 'editor': 417,\n",
       " 'billion': 418,\n",
       " 'third': 419,\n",
       " 'until': 420,\n",
       " 'went': 421,\n",
       " 'open': 422,\n",
       " 'held': 423,\n",
       " 'june': 424,\n",
       " 'british': 425,\n",
       " 'became': 426,\n",
       " 'men': 427,\n",
       " '11': 428,\n",
       " 'past': 429,\n",
       " 'very': 430,\n",
       " 'n.j.': 431,\n",
       " 'come': 432,\n",
       " 'reported': 433,\n",
       " 'such': 434,\n",
       " '2006': 435,\n",
       " 'old': 436,\n",
       " 'these': 437,\n",
       " 'name': 438,\n",
       " 'vice': 439,\n",
       " 'july': 440,\n",
       " 'theater': 441,\n",
       " 'good': 442,\n",
       " '2003': 443,\n",
       " 'r.': 444,\n",
       " 'least': 445,\n",
       " 'beloved': 446,\n",
       " 'going': 447,\n",
       " 'worked': 448,\n",
       " '30': 449,\n",
       " 'does': 450,\n",
       " 'agency': 451,\n",
       " 'says': 452,\n",
       " 'plan': 453,\n",
       " 'conference': 454,\n",
       " 'works': 455,\n",
       " 'williams': 456,\n",
       " 'announced': 457,\n",
       " 'firm': 458,\n",
       " 'mike': 459,\n",
       " 'each': 460,\n",
       " 'received': 461,\n",
       " 'calif.': 462,\n",
       " 'syria': 463,\n",
       " 'region': 464,\n",
       " 'afghanistan': 465,\n",
       " 'capital': 466,\n",
       " 'named': 467,\n",
       " 'no.': 468,\n",
       " 'head': 469,\n",
       " 'put': 470,\n",
       " 'orleans': 471,\n",
       " 'outside': 472,\n",
       " 'governor': 473,\n",
       " 'television': 474,\n",
       " 'money': 475,\n",
       " 'a.': 476,\n",
       " 'martin': 477,\n",
       " 'mayor': 478,\n",
       " 'building': 479,\n",
       " 'already': 480,\n",
       " 'games': 481,\n",
       " 'march': 482,\n",
       " 'players': 483,\n",
       " 'black': 484,\n",
       " 'church': 485,\n",
       " 'houston': 486,\n",
       " 'red': 487,\n",
       " 'market': 488,\n",
       " 'away': 489,\n",
       " 'loving': 490,\n",
       " 'm.': 491,\n",
       " 'point': 492,\n",
       " 'women': 493,\n",
       " 'scott': 494,\n",
       " 'less': 495,\n",
       " 'without': 496,\n",
       " 'includes': 497,\n",
       " 'lives': 498,\n",
       " 'real': 499,\n",
       " 'use': 500,\n",
       " 'jr.': 501,\n",
       " 'victory': 502,\n",
       " 'smith': 503,\n",
       " 'joseph': 504,\n",
       " '15': 505,\n",
       " 'research': 506,\n",
       " 'never': 507,\n",
       " 'plans': 508,\n",
       " 'largest': 509,\n",
       " 'hill': 510,\n",
       " 'massachusetts': 511,\n",
       " 'sister': 512,\n",
       " 'working': 513,\n",
       " 'see': 514,\n",
       " 'carolina': 515,\n",
       " 'columbia': 516,\n",
       " 'council': 517,\n",
       " 'summer': 518,\n",
       " '8': 519,\n",
       " 'directed': 520,\n",
       " 'production': 521,\n",
       " 'too': 522,\n",
       " 'bay': 523,\n",
       " 'me': 524,\n",
       " 'lost': 525,\n",
       " 'member': 526,\n",
       " 'northern': 527,\n",
       " '3': 528,\n",
       " 'report': 529,\n",
       " 'policy': 530,\n",
       " 'whether': 531,\n",
       " 'role': 532,\n",
       " 'close': 533,\n",
       " 'behind': 534,\n",
       " 'visit': 535,\n",
       " 'de': 536,\n",
       " 'bob': 537,\n",
       " 'bronx': 538,\n",
       " 'institute': 539,\n",
       " 'board': 540,\n",
       " 'met': 541,\n",
       " 'move': 542,\n",
       " 'nearly': 543,\n",
       " 'lead': 544,\n",
       " 'included': 545,\n",
       " 'economic': 546,\n",
       " 'weeks': 547,\n",
       " 'official': 548,\n",
       " 'village': 549,\n",
       " 'force': 550,\n",
       " 'gaza': 551,\n",
       " 'line': 552,\n",
       " 'asked': 553,\n",
       " 'death': 554,\n",
       " 'e.': 555,\n",
       " 'd.': 556,\n",
       " 'local': 557,\n",
       " 'jack': 558,\n",
       " 'trying': 559,\n",
       " 'killed': 560,\n",
       " 'married': 561,\n",
       " 'making': 562,\n",
       " 'hall': 563,\n",
       " '?': 564,\n",
       " 'pennsylvania': 565,\n",
       " 'democrats': 566,\n",
       " 'cities': 567,\n",
       " 'half': 568,\n",
       " 'miami': 569,\n",
       " 'every': 570,\n",
       " 'lee': 571,\n",
       " 'atlanta': 572,\n",
       " 'number': 573,\n",
       " 'large': 574,\n",
       " 'energy': 575,\n",
       " 'devoted': 576,\n",
       " 'development': 577,\n",
       " 'palestinian': 578,\n",
       " 'frank': 579,\n",
       " '12': 580,\n",
       " 'expected': 581,\n",
       " 'australia': 582,\n",
       " '2002': 583,\n",
       " 'pakistan': 584,\n",
       " 'steve': 585,\n",
       " 'april': 586,\n",
       " 'w.': 587,\n",
       " 'minutes': 588,\n",
       " 'earlier': 589,\n",
       " 'army': 590,\n",
       " 'press': 591,\n",
       " 'think': 592,\n",
       " 'chinese': 593,\n",
       " 'rights': 594,\n",
       " 'club': 595,\n",
       " 'private': 596,\n",
       " 'final': 597,\n",
       " '5': 598,\n",
       " 'interview': 599,\n",
       " 'western': 600,\n",
       " 'himself': 601,\n",
       " 'race': 602,\n",
       " 'miller': 603,\n",
       " 'start': 604,\n",
       " 'story': 605,\n",
       " 'helped': 606,\n",
       " 'spain': 607,\n",
       " 'job': 608,\n",
       " 'jackson': 609,\n",
       " 'louis': 610,\n",
       " 'running': 611,\n",
       " 'daniel': 612,\n",
       " 'spent': 613,\n",
       " 'troops': 614,\n",
       " 'star': 615,\n",
       " 'field': 616,\n",
       " '6': 617,\n",
       " 'almost': 618,\n",
       " 'leading': 619,\n",
       " 'sent': 620,\n",
       " 'friends': 621,\n",
       " 'joe': 622,\n",
       " 'community': 623,\n",
       " '%': 624,\n",
       " 'tour': 625,\n",
       " 'health': 626,\n",
       " 'live': 627,\n",
       " 'coast': 628,\n",
       " 'andrew': 629,\n",
       " 'effort': 630,\n",
       " 'having': 631,\n",
       " '25': 632,\n",
       " 'project': 633,\n",
       " 'financial': 634,\n",
       " 'saying': 635,\n",
       " 'services': 636,\n",
       " 'us': 637,\n",
       " 'arts': 638,\n",
       " 'republicans': 639,\n",
       " 'stephen': 640,\n",
       " 'border': 641,\n",
       " 'defense': 642,\n",
       " 'road': 643,\n",
       " 'free': 644,\n",
       " 'air': 645,\n",
       " 'talks': 646,\n",
       " 'mary': 647,\n",
       " '4': 648,\n",
       " 'hospital': 649,\n",
       " 'wrote': 650,\n",
       " 'friend': 651,\n",
       " 'nation': 652,\n",
       " 'students': 653,\n",
       " 'trip': 654,\n",
       " 'site': 655,\n",
       " 'arizona': 656,\n",
       " 'division': 657,\n",
       " 'jim': 658,\n",
       " 'love': 659,\n",
       " 'brian': 660,\n",
       " 'l.': 661,\n",
       " 'hussein': 662,\n",
       " 'grew': 663,\n",
       " 'officer': 664,\n",
       " 'often': 665,\n",
       " 'fort': 666,\n",
       " 'gave': 667,\n",
       " 'career': 668,\n",
       " 'israeli': 669,\n",
       " 'gov.': 670,\n",
       " 'beijing': 671,\n",
       " 'lived': 672,\n",
       " 'although': 673,\n",
       " 'woman': 674,\n",
       " 'tony': 675,\n",
       " 'return': 676,\n",
       " '9': 677,\n",
       " 'toward': 678,\n",
       " 'rice': 679,\n",
       " 'medical': 680,\n",
       " 'started': 681,\n",
       " 'al': 682,\n",
       " 'decision': 683,\n",
       " 'seven': 684,\n",
       " 'sept.': 685,\n",
       " 'c.': 686,\n",
       " 'better': 687,\n",
       " 'given': 688,\n",
       " 'harvard': 689,\n",
       " '7': 690,\n",
       " 'lake': 691,\n",
       " 'points': 692,\n",
       " 'attacks': 693,\n",
       " 'control': 694,\n",
       " 'howard': 695,\n",
       " 'taken': 696,\n",
       " 'whom': 697,\n",
       " 'detroit': 698,\n",
       " 'living': 699,\n",
       " 'yankees': 700,\n",
       " 'give': 701,\n",
       " 'yet': 702,\n",
       " 'again': 703,\n",
       " 'want': 704,\n",
       " 'playing': 705,\n",
       " '100': 706,\n",
       " 'judge': 707,\n",
       " 'intelligence': 708,\n",
       " 'eastern': 709,\n",
       " 'h.': 710,\n",
       " 'chris': 711,\n",
       " 'jones': 712,\n",
       " 'hotel': 713,\n",
       " 'susan': 714,\n",
       " 'media': 715,\n",
       " 'released': 716,\n",
       " 'hit': 717,\n",
       " 'written': 718,\n",
       " 'taking': 719,\n",
       " 'seattle': 720,\n",
       " 'westchester': 721,\n",
       " 'opened': 722,\n",
       " 'forces': 723,\n",
       " 'example': 724,\n",
       " 'elizabeth': 725,\n",
       " 'tomorrow': 726,\n",
       " 'louisiana': 727,\n",
       " 'got': 728,\n",
       " \"'re\": 729,\n",
       " 'grandfather': 730,\n",
       " 's.': 731,\n",
       " 'organization': 732,\n",
       " 'agreement': 733,\n",
       " 'call': 734,\n",
       " 'lawyer': 735,\n",
       " 'places': 736,\n",
       " 'fall': 737,\n",
       " 'partner': 738,\n",
       " 'efforts': 739,\n",
       " 'record': 740,\n",
       " 'face': 741,\n",
       " 'spokesman': 742,\n",
       " 'important': 743,\n",
       " 'enough': 744,\n",
       " 'built': 745,\n",
       " '2000': 746,\n",
       " 'green': 747,\n",
       " 'know': 748,\n",
       " 'nbc': 749,\n",
       " 'davis': 750,\n",
       " 'christopher': 751,\n",
       " 'industry': 752,\n",
       " 'system': 753,\n",
       " 'author': 754,\n",
       " 'warner': 755,\n",
       " 'edward': 756,\n",
       " 'graduated': 757,\n",
       " 'residents': 758,\n",
       " 'ford': 759,\n",
       " 'commission': 760,\n",
       " 'henry': 761,\n",
       " 'player': 762,\n",
       " 'agreed': 763,\n",
       " 'jason': 764,\n",
       " 'look': 765,\n",
       " '50': 766,\n",
       " 'turned': 767,\n",
       " 'correction': 768,\n",
       " 'find': 769,\n",
       " '18': 770,\n",
       " 'hours': 771,\n",
       " 'current': 772,\n",
       " '2001': 773,\n",
       " 'owner': 774,\n",
       " 'artists': 775,\n",
       " 'hudson': 776,\n",
       " 'king': 777,\n",
       " 'together': 778,\n",
       " 'grandmother': 779,\n",
       " 'jordan': 780,\n",
       " 'served': 781,\n",
       " 'joined': 782,\n",
       " 'cbs': 783,\n",
       " 'justice': 784,\n",
       " 'special': 785,\n",
       " 'iraqi': 786,\n",
       " 'issue': 787,\n",
       " 'relations': 788,\n",
       " 'majority': 789,\n",
       " 'b.': 790,\n",
       " 'room': 791,\n",
       " 'barbara': 792,\n",
       " 'starting': 793,\n",
       " 'degree': 794,\n",
       " 'your': 795,\n",
       " 'candidate': 796,\n",
       " '16': 797,\n",
       " 'sons': 798,\n",
       " 'signed': 799,\n",
       " '14': 800,\n",
       " 'operations': 801,\n",
       " 'dallas': 802,\n",
       " 'parts': 803,\n",
       " 'retired': 804,\n",
       " 'corporation': 805,\n",
       " 'estate': 806,\n",
       " 'meet': 807,\n",
       " 'offer': 808,\n",
       " 'election': 809,\n",
       " 'brought': 810,\n",
       " 'saddam': 811,\n",
       " 'seen': 812,\n",
       " 'change': 813,\n",
       " 'schools': 814,\n",
       " 'french': 815,\n",
       " 'study': 816,\n",
       " 'main': 817,\n",
       " 'steven': 818,\n",
       " 'cup': 819,\n",
       " 'need': 820,\n",
       " 'ny': 821,\n",
       " 'civil': 822,\n",
       " 'eric': 823,\n",
       " '\\\\*': 824,\n",
       " 'valley': 825,\n",
       " 'movie': 826,\n",
       " 'sports': 827,\n",
       " 'growing': 828,\n",
       " 'list': 829,\n",
       " 'fox': 830,\n",
       " 'airport': 831,\n",
       " 'morning': 832,\n",
       " 'technology': 833,\n",
       " 'festival': 834,\n",
       " 'vote': 835,\n",
       " 'egypt': 836,\n",
       " 'lot': 837,\n",
       " 'brazil': 838,\n",
       " 'groups': 839,\n",
       " 'sales': 840,\n",
       " 'newark': 841,\n",
       " 'restaurant': 842,\n",
       " 'mrs.': 843,\n",
       " 'taiwan': 844,\n",
       " 'possible': 845,\n",
       " 'teams': 846,\n",
       " '13': 847,\n",
       " 'jonathan': 848,\n",
       " 'network': 849,\n",
       " 'attack': 850,\n",
       " 'gas': 851,\n",
       " 'base': 852,\n",
       " 'page': 853,\n",
       " 'weekend': 854,\n",
       " 'georgia': 855,\n",
       " 'assistant': 856,\n",
       " 'kansas': 857,\n",
       " 'why': 858,\n",
       " 'kennedy': 859,\n",
       " 'americans': 860,\n",
       " 'peace': 861,\n",
       " 'stop': 862,\n",
       " 'parents': 863,\n",
       " 'win': 864,\n",
       " 'investigation': 865,\n",
       " 'pay': 866,\n",
       " 'kevin': 867,\n",
       " 'raised': 868,\n",
       " 'addition': 869,\n",
       " 'f.': 870,\n",
       " 'keep': 871,\n",
       " 'eight': 872,\n",
       " 'stars': 873,\n",
       " 'short': 874,\n",
       " 'wanted': 875,\n",
       " 'future': 876,\n",
       " 'especially': 877,\n",
       " 'within': 878,\n",
       " 'produced': 879,\n",
       " 'similar': 880,\n",
       " 'january': 881,\n",
       " 'jeff': 882,\n",
       " 'plays': 883,\n",
       " 'staff': 884,\n",
       " 'allen': 885,\n",
       " 'brothers': 886,\n",
       " 'football': 887,\n",
       " 'weapons': 888,\n",
       " 'social': 889,\n",
       " 'native': 890,\n",
       " 'age': 891,\n",
       " 'association': 892,\n",
       " 'michigan': 893,\n",
       " 'course': 894,\n",
       " 'global': 895,\n",
       " 'human': 896,\n",
       " 'sudan': 897,\n",
       " 'different': 898,\n",
       " 'something': 899,\n",
       " 'moving': 900,\n",
       " '17': 901,\n",
       " 'soon': 902,\n",
       " 'runs': 903,\n",
       " 'anthony': 904,\n",
       " 'travel': 905,\n",
       " 'ambassador': 906,\n",
       " 'ever': 907,\n",
       " 'moscow': 908,\n",
       " 'wilson': 909,\n",
       " 'fla.': 910,\n",
       " 'november': 911,\n",
       " 'mets': 912,\n",
       " 'car': 913,\n",
       " 'education': 914,\n",
       " 'strong': 915,\n",
       " 'despite': 916,\n",
       " 'statement': 917,\n",
       " 'port': 918,\n",
       " 'full': 919,\n",
       " 'areas': 920,\n",
       " 'u.s.': 921,\n",
       " 'turkey': 922,\n",
       " 'workers': 923,\n",
       " 'arab': 924,\n",
       " 'lincoln': 925,\n",
       " 'created': 926,\n",
       " 'sold': 927,\n",
       " 'management': 928,\n",
       " 'streets': 929,\n",
       " 'likely': 930,\n",
       " 'investment': 931,\n",
       " 'morgan': 932,\n",
       " 'coming': 933,\n",
       " 'writer': 934,\n",
       " '22': 935,\n",
       " 'heights': 936,\n",
       " 'alan': 937,\n",
       " 'perhaps': 938,\n",
       " 'mississippi': 939,\n",
       " 'clear': 940,\n",
       " 'tonight': 941,\n",
       " 'thousands': 942,\n",
       " '-': 943,\n",
       " 'larry': 944,\n",
       " 'scheduled': 945,\n",
       " 'rose': 946,\n",
       " 'food': 947,\n",
       " 'evening': 948,\n",
       " 'biggest': 949,\n",
       " 'owned': 950,\n",
       " '40': 951,\n",
       " 'books': 952,\n",
       " 'aid': 953,\n",
       " 'kind': 954,\n",
       " 'diego': 955,\n",
       " 'build': 956,\n",
       " 'neighborhood': 957,\n",
       " 'front': 958,\n",
       " 'ii': 959,\n",
       " 'misstated': 960,\n",
       " 'title': 961,\n",
       " 'mass.': 962,\n",
       " 'always': 963,\n",
       " 'land': 964,\n",
       " 'station': 965,\n",
       " 'spring': 966,\n",
       " 'matthew': 967,\n",
       " 'guard': 968,\n",
       " 'radio': 969,\n",
       " 'atlantic': 970,\n",
       " 'popular': 971,\n",
       " '60': 972,\n",
       " 'sharon': 973,\n",
       " 'student': 974,\n",
       " 'lower': 975,\n",
       " 'grand': 976,\n",
       " 'toronto': 977,\n",
       " '24': 978,\n",
       " 'particularly': 979,\n",
       " 'tennessee': 980,\n",
       " 'modern': 981,\n",
       " 'must': 982,\n",
       " 'kong': 983,\n",
       " 'collection': 984,\n",
       " 'charges': 985,\n",
       " 'calls': 986,\n",
       " 'space': 987,\n",
       " 'hong': 988,\n",
       " 'december': 989,\n",
       " 'position': 990,\n",
       " 'tax': 991,\n",
       " 'square': 992,\n",
       " 'a.m.': 993,\n",
       " 'taylor': 994,\n",
       " 'looking': 995,\n",
       " 'shot': 996,\n",
       " 'information': 997,\n",
       " 'band': 998,\n",
       " 'pittsburgh': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.key2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_set = Index()   # 实体类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_set.load(\"data/NYT_CoType/tag2id.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_labels = Index()      # 关系类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_labels.load('data/NYT_CoType/relation_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/people/person/nationality': 0,\n",
       " '/location/country/capital': 1,\n",
       " '/location/location/contains': 2,\n",
       " '/people/deceased_person/place_of_death': 3,\n",
       " '/people/person/children': 4,\n",
       " '/people/person/place_of_birth': 5,\n",
       " '/people/person/place_lived': 6,\n",
       " '/location/country/administrative_divisions': 7,\n",
       " '/location/administrative_division/country': 8,\n",
       " '/business/person/company': 9,\n",
       " '/location/neighborhood/neighborhood_of': 10,\n",
       " '/business/company/place_founded': 11,\n",
       " '/business/company/founders': 12,\n",
       " '/sports/sports_team_location/teams': 13,\n",
       " '/sports/sports_team/location': 14,\n",
       " '/business/company_shareholder/major_shareholder_of': 15,\n",
       " '/business/company/major_shareholders': 16,\n",
       " '/people/ethnicity/people': 17,\n",
       " '/people/person/ethnicity': 18,\n",
       " '/business/company/advisors': 19,\n",
       " '/people/person/religion': 20,\n",
       " '/people/ethnicity/geographic_distribution': 21,\n",
       " '/people/person/profession': 22,\n",
       " '/business/company/industry': 23,\n",
       " 'None': 24}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_labels.key2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-/people/person/nationality-1': 1,\n",
       " 'B-/people/person/nationality-2': 2,\n",
       " 'I-/people/person/nationality-1': 3,\n",
       " 'I-/people/person/nationality-2': 4,\n",
       " 'E-/people/person/nationality-1': 5,\n",
       " 'E-/people/person/nationality-2': 6,\n",
       " 'S-/people/person/nationality-1': 7,\n",
       " 'S-/people/person/nationality-2': 8,\n",
       " 'B-/location/country/capital-1': 9,\n",
       " 'B-/location/country/capital-2': 10,\n",
       " 'I-/location/country/capital-1': 11,\n",
       " 'I-/location/country/capital-2': 12,\n",
       " 'E-/location/country/capital-1': 13,\n",
       " 'E-/location/country/capital-2': 14,\n",
       " 'S-/location/country/capital-1': 15,\n",
       " 'S-/location/country/capital-2': 16,\n",
       " 'B-/location/location/contains-1': 17,\n",
       " 'B-/location/location/contains-2': 18,\n",
       " 'I-/location/location/contains-1': 19,\n",
       " 'I-/location/location/contains-2': 20,\n",
       " 'E-/location/location/contains-1': 21,\n",
       " 'E-/location/location/contains-2': 22,\n",
       " 'S-/location/location/contains-1': 23,\n",
       " 'S-/location/location/contains-2': 24,\n",
       " 'B-/people/deceased_person/place_of_death-1': 25,\n",
       " 'B-/people/deceased_person/place_of_death-2': 26,\n",
       " 'I-/people/deceased_person/place_of_death-1': 27,\n",
       " 'I-/people/deceased_person/place_of_death-2': 28,\n",
       " 'E-/people/deceased_person/place_of_death-1': 29,\n",
       " 'E-/people/deceased_person/place_of_death-2': 30,\n",
       " 'S-/people/deceased_person/place_of_death-1': 31,\n",
       " 'S-/people/deceased_person/place_of_death-2': 32,\n",
       " 'B-/people/person/children-1': 33,\n",
       " 'B-/people/person/children-2': 34,\n",
       " 'I-/people/person/children-1': 35,\n",
       " 'I-/people/person/children-2': 36,\n",
       " 'E-/people/person/children-1': 37,\n",
       " 'E-/people/person/children-2': 38,\n",
       " 'S-/people/person/children-1': 39,\n",
       " 'S-/people/person/children-2': 40,\n",
       " 'B-/people/person/place_of_birth-1': 41,\n",
       " 'B-/people/person/place_of_birth-2': 42,\n",
       " 'I-/people/person/place_of_birth-1': 43,\n",
       " 'I-/people/person/place_of_birth-2': 44,\n",
       " 'E-/people/person/place_of_birth-1': 45,\n",
       " 'E-/people/person/place_of_birth-2': 46,\n",
       " 'S-/people/person/place_of_birth-1': 47,\n",
       " 'S-/people/person/place_of_birth-2': 48,\n",
       " 'B-/people/person/place_lived-1': 49,\n",
       " 'B-/people/person/place_lived-2': 50,\n",
       " 'I-/people/person/place_lived-1': 51,\n",
       " 'I-/people/person/place_lived-2': 52,\n",
       " 'E-/people/person/place_lived-1': 53,\n",
       " 'E-/people/person/place_lived-2': 54,\n",
       " 'S-/people/person/place_lived-1': 55,\n",
       " 'S-/people/person/place_lived-2': 56,\n",
       " 'B-/location/country/administrative_divisions-1': 57,\n",
       " 'B-/location/country/administrative_divisions-2': 58,\n",
       " 'I-/location/country/administrative_divisions-1': 59,\n",
       " 'I-/location/country/administrative_divisions-2': 60,\n",
       " 'E-/location/country/administrative_divisions-1': 61,\n",
       " 'E-/location/country/administrative_divisions-2': 62,\n",
       " 'S-/location/country/administrative_divisions-1': 63,\n",
       " 'S-/location/country/administrative_divisions-2': 64,\n",
       " 'B-/location/administrative_division/country-1': 65,\n",
       " 'B-/location/administrative_division/country-2': 66,\n",
       " 'I-/location/administrative_division/country-1': 67,\n",
       " 'I-/location/administrative_division/country-2': 68,\n",
       " 'E-/location/administrative_division/country-1': 69,\n",
       " 'E-/location/administrative_division/country-2': 70,\n",
       " 'S-/location/administrative_division/country-1': 71,\n",
       " 'S-/location/administrative_division/country-2': 72,\n",
       " 'B-/business/person/company-1': 73,\n",
       " 'B-/business/person/company-2': 74,\n",
       " 'I-/business/person/company-1': 75,\n",
       " 'I-/business/person/company-2': 76,\n",
       " 'E-/business/person/company-1': 77,\n",
       " 'E-/business/person/company-2': 78,\n",
       " 'S-/business/person/company-1': 79,\n",
       " 'S-/business/person/company-2': 80,\n",
       " 'B-/location/neighborhood/neighborhood_of-1': 81,\n",
       " 'B-/location/neighborhood/neighborhood_of-2': 82,\n",
       " 'I-/location/neighborhood/neighborhood_of-1': 83,\n",
       " 'I-/location/neighborhood/neighborhood_of-2': 84,\n",
       " 'E-/location/neighborhood/neighborhood_of-1': 85,\n",
       " 'E-/location/neighborhood/neighborhood_of-2': 86,\n",
       " 'S-/location/neighborhood/neighborhood_of-1': 87,\n",
       " 'S-/location/neighborhood/neighborhood_of-2': 88,\n",
       " 'B-/business/company/place_founded-1': 89,\n",
       " 'B-/business/company/place_founded-2': 90,\n",
       " 'I-/business/company/place_founded-1': 91,\n",
       " 'I-/business/company/place_founded-2': 92,\n",
       " 'E-/business/company/place_founded-1': 93,\n",
       " 'E-/business/company/place_founded-2': 94,\n",
       " 'S-/business/company/place_founded-1': 95,\n",
       " 'S-/business/company/place_founded-2': 96,\n",
       " 'B-/business/company/founders-1': 97,\n",
       " 'B-/business/company/founders-2': 98,\n",
       " 'I-/business/company/founders-1': 99,\n",
       " 'I-/business/company/founders-2': 100,\n",
       " 'E-/business/company/founders-1': 101,\n",
       " 'E-/business/company/founders-2': 102,\n",
       " 'S-/business/company/founders-1': 103,\n",
       " 'S-/business/company/founders-2': 104,\n",
       " 'B-/sports/sports_team_location/teams-1': 105,\n",
       " 'B-/sports/sports_team_location/teams-2': 106,\n",
       " 'I-/sports/sports_team_location/teams-1': 107,\n",
       " 'I-/sports/sports_team_location/teams-2': 108,\n",
       " 'E-/sports/sports_team_location/teams-1': 109,\n",
       " 'E-/sports/sports_team_location/teams-2': 110,\n",
       " 'S-/sports/sports_team_location/teams-1': 111,\n",
       " 'S-/sports/sports_team_location/teams-2': 112,\n",
       " 'B-/sports/sports_team/location-1': 113,\n",
       " 'B-/sports/sports_team/location-2': 114,\n",
       " 'I-/sports/sports_team/location-1': 115,\n",
       " 'I-/sports/sports_team/location-2': 116,\n",
       " 'E-/sports/sports_team/location-1': 117,\n",
       " 'E-/sports/sports_team/location-2': 118,\n",
       " 'S-/sports/sports_team/location-1': 119,\n",
       " 'S-/sports/sports_team/location-2': 120,\n",
       " 'B-/business/company_shareholder/major_shareholder_of-1': 121,\n",
       " 'B-/business/company_shareholder/major_shareholder_of-2': 122,\n",
       " 'I-/business/company_shareholder/major_shareholder_of-1': 123,\n",
       " 'I-/business/company_shareholder/major_shareholder_of-2': 124,\n",
       " 'E-/business/company_shareholder/major_shareholder_of-1': 125,\n",
       " 'E-/business/company_shareholder/major_shareholder_of-2': 126,\n",
       " 'S-/business/company_shareholder/major_shareholder_of-1': 127,\n",
       " 'S-/business/company_shareholder/major_shareholder_of-2': 128,\n",
       " 'B-/business/company/major_shareholders-1': 129,\n",
       " 'B-/business/company/major_shareholders-2': 130,\n",
       " 'I-/business/company/major_shareholders-1': 131,\n",
       " 'I-/business/company/major_shareholders-2': 132,\n",
       " 'E-/business/company/major_shareholders-1': 133,\n",
       " 'E-/business/company/major_shareholders-2': 134,\n",
       " 'S-/business/company/major_shareholders-1': 135,\n",
       " 'S-/business/company/major_shareholders-2': 136,\n",
       " 'B-/people/ethnicity/people-1': 137,\n",
       " 'B-/people/ethnicity/people-2': 138,\n",
       " 'I-/people/ethnicity/people-1': 139,\n",
       " 'I-/people/ethnicity/people-2': 140,\n",
       " 'E-/people/ethnicity/people-1': 141,\n",
       " 'E-/people/ethnicity/people-2': 142,\n",
       " 'S-/people/ethnicity/people-1': 143,\n",
       " 'S-/people/ethnicity/people-2': 144,\n",
       " 'B-/people/person/ethnicity-1': 145,\n",
       " 'B-/people/person/ethnicity-2': 146,\n",
       " 'I-/people/person/ethnicity-1': 147,\n",
       " 'I-/people/person/ethnicity-2': 148,\n",
       " 'E-/people/person/ethnicity-1': 149,\n",
       " 'E-/people/person/ethnicity-2': 150,\n",
       " 'S-/people/person/ethnicity-1': 151,\n",
       " 'S-/people/person/ethnicity-2': 152,\n",
       " 'B-/business/company/advisors-1': 153,\n",
       " 'B-/business/company/advisors-2': 154,\n",
       " 'I-/business/company/advisors-1': 155,\n",
       " 'I-/business/company/advisors-2': 156,\n",
       " 'E-/business/company/advisors-1': 157,\n",
       " 'E-/business/company/advisors-2': 158,\n",
       " 'S-/business/company/advisors-1': 159,\n",
       " 'S-/business/company/advisors-2': 160,\n",
       " 'B-/people/person/religion-1': 161,\n",
       " 'B-/people/person/religion-2': 162,\n",
       " 'I-/people/person/religion-1': 163,\n",
       " 'I-/people/person/religion-2': 164,\n",
       " 'E-/people/person/religion-1': 165,\n",
       " 'E-/people/person/religion-2': 166,\n",
       " 'S-/people/person/religion-1': 167,\n",
       " 'S-/people/person/religion-2': 168,\n",
       " 'B-/people/ethnicity/geographic_distribution-1': 169,\n",
       " 'B-/people/ethnicity/geographic_distribution-2': 170,\n",
       " 'I-/people/ethnicity/geographic_distribution-1': 171,\n",
       " 'I-/people/ethnicity/geographic_distribution-2': 172,\n",
       " 'E-/people/ethnicity/geographic_distribution-1': 173,\n",
       " 'E-/people/ethnicity/geographic_distribution-2': 174,\n",
       " 'S-/people/ethnicity/geographic_distribution-1': 175,\n",
       " 'S-/people/ethnicity/geographic_distribution-2': 176,\n",
       " 'B-/people/person/profession-1': 177,\n",
       " 'B-/people/person/profession-2': 178,\n",
       " 'I-/people/person/profession-1': 179,\n",
       " 'I-/people/person/profession-2': 180,\n",
       " 'E-/people/person/profession-1': 181,\n",
       " 'E-/people/person/profession-2': 182,\n",
       " 'S-/people/person/profession-1': 183,\n",
       " 'S-/people/person/profession-2': 184,\n",
       " 'B-/business/company/industry-1': 185,\n",
       " 'B-/business/company/industry-2': 186,\n",
       " 'I-/business/company/industry-1': 187,\n",
       " 'I-/business/company/industry-2': 188,\n",
       " 'E-/business/company/industry-1': 189,\n",
       " 'E-/business/company/industry-2': 190,\n",
       " 'S-/business/company/industry-1': 191,\n",
       " 'S-/business/company/industry-2': 192}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set.key2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load('data/NYT_CoType/train.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load('data/NYT_CoType/test.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([670,\n",
       "  1158,\n",
       "  40526,\n",
       "  5,\n",
       "  1018,\n",
       "  2037,\n",
       "  3,\n",
       "  81,\n",
       "  626,\n",
       "  395,\n",
       "  48,\n",
       "  228,\n",
       "  9,\n",
       "  6048,\n",
       "  10868,\n",
       "  801,\n",
       "  15,\n",
       "  3,\n",
       "  2131,\n",
       "  2866,\n",
       "  113,\n",
       "  52,\n",
       "  81,\n",
       "  5755,\n",
       "  346,\n",
       "  13,\n",
       "  97,\n",
       "  427,\n",
       "  37,\n",
       "  300,\n",
       "  88,\n",
       "  7,\n",
       "  3,\n",
       "  1713,\n",
       "  228,\n",
       "  126,\n",
       "  5,\n",
       "  15086,\n",
       "  63,\n",
       "  680,\n",
       "  7733,\n",
       "  6],\n",
       " [[42,\n",
       "   24,\n",
       "   31,\n",
       "   75,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [55,\n",
       "   18,\n",
       "   22,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [51,\n",
       "   10,\n",
       "   32,\n",
       "   21,\n",
       "   14,\n",
       "   23,\n",
       "   29,\n",
       "   34,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [24,\n",
       "   15,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [48,\n",
       "   18,\n",
       "   23,\n",
       "   23,\n",
       "   14,\n",
       "   28,\n",
       "   24,\n",
       "   29,\n",
       "   10,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [24,\n",
       "   27,\n",
       "   13,\n",
       "   14,\n",
       "   27,\n",
       "   14,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [28,\n",
       "   29,\n",
       "   10,\n",
       "   29,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [17,\n",
       "   14,\n",
       "   10,\n",
       "   21,\n",
       "   29,\n",
       "   17,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [13,\n",
       "   14,\n",
       "   25,\n",
       "   10,\n",
       "   27,\n",
       "   29,\n",
       "   22,\n",
       "   14,\n",
       "   23,\n",
       "   29,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   18,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [22,\n",
       "   24,\n",
       "   23,\n",
       "   29,\n",
       "   17,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   24,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [22,\n",
       "   24,\n",
       "   23,\n",
       "   18,\n",
       "   29,\n",
       "   24,\n",
       "   27,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [13,\n",
       "   10,\n",
       "   34,\n",
       "   74,\n",
       "   29,\n",
       "   24,\n",
       "   74,\n",
       "   13,\n",
       "   10,\n",
       "   34,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [24,\n",
       "   25,\n",
       "   14,\n",
       "   27,\n",
       "   10,\n",
       "   29,\n",
       "   18,\n",
       "   24,\n",
       "   23,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [10,\n",
       "   29,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [48,\n",
       "   18,\n",
       "   23,\n",
       "   23,\n",
       "   14,\n",
       "   10,\n",
       "   25,\n",
       "   24,\n",
       "   21,\n",
       "   18,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [57,\n",
       "   14,\n",
       "   29,\n",
       "   14,\n",
       "   27,\n",
       "   10,\n",
       "   23,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [43,\n",
       "   24,\n",
       "   22,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [10,\n",
       "   15,\n",
       "   29,\n",
       "   14,\n",
       "   27,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [28,\n",
       "   29,\n",
       "   10,\n",
       "   29,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [18,\n",
       "   23,\n",
       "   28,\n",
       "   25,\n",
       "   14,\n",
       "   12,\n",
       "   29,\n",
       "   24,\n",
       "   27,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [15,\n",
       "   24,\n",
       "   30,\n",
       "   23,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   10,\n",
       "   29,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   27,\n",
       "   14,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [22,\n",
       "   14,\n",
       "   23,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [17,\n",
       "   10,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [13,\n",
       "   18,\n",
       "   14,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   14,\n",
       "   27,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [18,\n",
       "   23,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [29,\n",
       "   17,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [25,\n",
       "   27,\n",
       "   14,\n",
       "   31,\n",
       "   18,\n",
       "   24,\n",
       "   30,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [22,\n",
       "   24,\n",
       "   23,\n",
       "   29,\n",
       "   17,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [11,\n",
       "   14,\n",
       "   12,\n",
       "   10,\n",
       "   30,\n",
       "   28,\n",
       "   14,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [24,\n",
       "   15,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [23,\n",
       "   14,\n",
       "   16,\n",
       "   21,\n",
       "   14,\n",
       "   12,\n",
       "   29,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [24,\n",
       "   27,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [22,\n",
       "   14,\n",
       "   13,\n",
       "   18,\n",
       "   12,\n",
       "   10,\n",
       "   21,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [14,\n",
       "   27,\n",
       "   27,\n",
       "   24,\n",
       "   27,\n",
       "   28,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [75,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94]],\n",
       " [0,\n",
       "  49,\n",
       "  53,\n",
       "  0,\n",
       "  56,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(0.01 * len(train_data))\n",
    "train_data, val_data = random_split(train_data, [len(train_data)-val_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 44107,\n",
       " 21,\n",
       " 266,\n",
       " 84,\n",
       " 30,\n",
       " 1513,\n",
       " 187,\n",
       " 7,\n",
       " 3,\n",
       " 538,\n",
       " 4,\n",
       " 21,\n",
       " 868,\n",
       " 7,\n",
       " 19121,\n",
       " 2,\n",
       " 14,\n",
       " 115,\n",
       " 123,\n",
       " 6]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(data, breakpoints):\n",
    "    groups = [[] for _ in range(len(breakpoints)+1)]\n",
    "    for idx, item in enumerate(data):\n",
    "        i = bisect.bisect_left(breakpoints, len(item[0]))\n",
    "        groups[i].append(idx)\n",
    "    data_groups = [Subset(data, g) for g in groups]\n",
    "    return data_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_groups = group(train_data, [10, 20, 30, 40, 50, 60])\n",
    "val_data_groups = group(val_data, [10, 20, 30, 40, 50, 60])\n",
    "test_data_groups = group(test_data, [10, 20, 30, 40, 50, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = torch.tensor(np.load(\"data/NYT_CoType/word2vec.vectors.npy\"))\n",
    "word_embedding_size = word_embeddings.size(1)\n",
    "pad_embedding = torch.empty(1, word_embedding_size).uniform_(-0.5, 0.5)\n",
    "unk_embedding = torch.empty(1, word_embedding_size).uniform_(-0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = torch.cat([pad_embedding, unk_embedding, word_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47465, 300])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_channels = [args.emsize] + [args.char_nhid] * args.char_layers\n",
    "word_channels = [word_embedding_size + args.char_nhid] + [args.word_nhid] * args.word_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 50, 50, 50]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[350, 300, 300, 300]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"model.pt\"):\n",
    "    model=torch.load('model.pt')\n",
    "else:\n",
    "    model = Model(charset_size=len(charset), char_embedding_size=args.emsize, char_channels=char_channels,\n",
    "                  char_padding_idx=charset[\"<pad>\"], char_kernel_size=args.char_kernel_size, weight=word_embeddings,\n",
    "                  word_embedding_size=word_embedding_size, word_channels=word_channels,\n",
    "                  word_kernel_size=args.word_kernel_size, num_tag=len(tag_set), dropout=args.dropout,\n",
    "                  emb_dropout=args.emb_dropout).to(device)    # vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = [args.weight] * len(tag_set)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor(weight).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niuhao/anaconda2/envs/PYTH_1.6/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss(weight, size_average=False)\n",
    "optimizer = getattr(optim, args.optim)(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "lr = args.lr\n",
    "all_val_loss = []\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupBatchRandomSampler(object):\n",
    "    def __init__(self, data_groups, batch_size, drop_last):\n",
    "        self.batch_indices = []\n",
    "        for data_group in data_groups:\n",
    "            self.batch_indices.extend(list(BatchSampler(SubsetRandomSampler(data_group.indices),\n",
    "                                                        batch_size, drop_last=drop_last)))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.batch_indices[i] for i in torch.randperm(len(self.batch_indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train()\n",
    "model.train()\n",
    "total_loss = 0\n",
    "count = 0\n",
    "sampler = GroupBatchRandomSampler(train_data_groups, args.batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7093"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampler.batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[202991,\n",
       " 52820,\n",
       " 98562,\n",
       " 225404,\n",
       " 211013,\n",
       " 130004,\n",
       " 110339,\n",
       " 128196,\n",
       " 78333,\n",
       " 186118,\n",
       " 60559,\n",
       " 74588,\n",
       " 42842,\n",
       " 163144,\n",
       " 177977,\n",
       " 67215,\n",
       " 23235,\n",
       " 52733,\n",
       " 17306,\n",
       " 29014,\n",
       " 155352,\n",
       " 9532,\n",
       " 41117,\n",
       " 10049,\n",
       " 103004,\n",
       " 143077,\n",
       " 74849,\n",
       " 135856,\n",
       " 215603,\n",
       " 132474,\n",
       " 9404,\n",
       " 132062]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_indices = sampler.batch_indices[0]\n",
    "batch_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 函数 get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "batch = [data[idx] for idx in batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 109, 3092, 2, 1006, 2, 283, 1, 6],\n",
       " [[1, 0, 8, 2, 5, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94],\n",
       "  [40,\n",
       "   10,\n",
       "   28,\n",
       "   29,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [37,\n",
       "   24,\n",
       "   30,\n",
       "   21,\n",
       "   14,\n",
       "   31,\n",
       "   10,\n",
       "   27,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [73,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [38,\n",
       "   21,\n",
       "   14,\n",
       "   31,\n",
       "   14,\n",
       "   21,\n",
       "   10,\n",
       "   23,\n",
       "   13,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [73,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [50,\n",
       "   17,\n",
       "   18,\n",
       "   24,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94],\n",
       "  [4, 4, 1, 0, 6, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94],\n",
       "  [75,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94,\n",
       "   94]],\n",
       " [0, 0, 0, 0, 24, 0, 23, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, tokens, tags = zip(*sorted_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([33, 21, 3, 27051, 805, 2, 44, 27051, 4532, 6],\n",
       " [6759, 11, 68, 2342, 9, 780, 21, 8, 1413, 6],\n",
       " [57, 5, 3, 12754, 221, 5, 3625, 4, 946, 6],\n",
       " [33, 2446, 11057, 119, 291, 2, 207, 4, 91, 6],\n",
       " [2445, 4744, 2, 9799, 27413, 17794, 2, 27489, 2, 2154],\n",
       " [24, 21, 7684, 4, 672, 7, 1907, 2, 202, 6],\n",
       " [3035, 32, 3625, 20066, 4, 16193, 37, 2373, 7742, 6],\n",
       " [1, 109, 3092, 2, 1006, 2, 283, 1, 6],\n",
       " [2028, 3323, 47010, 2, 459, 19, 1, 211, 6],\n",
       " [4389, 41, 77, 6563, 2, 1609, 556, 7057, 6],\n",
       " [963, 795, 170, 2, 10371, 2, 2152, 4, 6985],\n",
       " [2146, 4, 1992, 26, 61, 1, 460, 69, 6],\n",
       " [3400, 216, 516, 126, 5, 3, 634, 6433, 6],\n",
       " [1543, 11105, 1999, 7808, 15, 177, 5884, 6, 10],\n",
       " [659, 2, 3025, 2, 120, 2, 494, 4, 2311],\n",
       " [764, 2, 629, 4, 1990, 1, 31, 1524, 6],\n",
       " [7, 3, 966, 2241, 20516, 757, 19, 516, 6],\n",
       " [24, 17, 1, 1, 2, 44, 1, 6],\n",
       " [1539, 1321, 83, 11, 11954, 4136, 103, 6],\n",
       " [32011, 217, 252, 2, 4849, 2, 1052, 6],\n",
       " [323, 5939, 2, 7567, 268, 25690, 2, 304],\n",
       " [371, 5, 3526, 2, 944, 4, 792, 6],\n",
       " [6632, 1537, 5, 523, 2136, 2, 101, 6],\n",
       " [387, 4663, 2, 10, 26, 7283, 6, 10],\n",
       " [28245, 2, 1970, 2, 1, 2, 20732],\n",
       " [33, 21, 30242, 2, 44, 5248, 6],\n",
       " [1877, 357, 2842, 18, 50, 1601, 6],\n",
       " [490, 371, 5, 4830, 4, 3521, 6],\n",
       " [277, 2, 10, 4227, 26, 6],\n",
       " [932, 1041, 4, 1560, 1951, 6],\n",
       " [7339, 2, 7289, 4, 187],\n",
       " [29085, 2, 277, 6])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 24, 0, 23, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 24, 0, 23, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 24, 0, 23, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 81, 85, 0, 88, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [24, 0, 23, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentences, lengths = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in sentences]),\n",
    "                                                    batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "padded_tokens, _ = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in tokens]),\n",
    "                                       batch_first=True, padding_value=charset[\"<pad>\"])\n",
    "padded_tags, _ = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in tags]),\n",
    "                                     batch_first=True, padding_value=tag_set[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  8,\n",
       "         8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  6,  6,  5,  4],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences.to(device)\n",
    "padded_tokens.to(device)\n",
    "padded_tags.to(device)\n",
    "lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_indices, data):\n",
    "    batch = [data[idx] for idx in batch_indices]\n",
    "    sorted_batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, tokens, tags = zip(*sorted_batch)\n",
    "\n",
    "    padded_sentences, lengths = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in sentences]),\n",
    "                                                    batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    padded_tokens, _ = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in tokens]),\n",
    "                                           batch_first=True, padding_value=charset[\"<pad>\"])\n",
    "    padded_tags, _ = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in tags]),\n",
    "                                         batch_first=True, padding_value=tag_set[\"O\"])\n",
    "\n",
    "    return padded_sentences.to(device), padded_tokens.to(device), padded_tags.to(device), lengths.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, tokens, targets, lengths = padded_sentences.to(device), padded_tokens.to(device), padded_tags.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(sentences, tokens)  # vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 193])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  8,\n",
       "         8,  8,  8,  8,  8,  8,  7,  7,  7,  7,  6,  6,  5,  4],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pack_padded_sequence(output, lengths, batch_first=True).data\n",
    "targets = pack_padded_sequence(targets, lengths, batch_first=True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([265])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([265, 193])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14105.5801, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "if args.clip > 0:\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss, precision, recall, f1 = evaluate(val_data_groups)\n",
    "# evaluate\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "count = 0\n",
    "TP = 0\n",
    "TP_FP = 0\n",
    "TP_FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_sampler = GroupBatchRandomSampler(val_data_groups, args.batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1375,\n",
       " 1353,\n",
       " 42,\n",
       " 173,\n",
       " 389,\n",
       " 885,\n",
       " 96,\n",
       " 2068,\n",
       " 676,\n",
       " 1429,\n",
       " 620,\n",
       " 652,\n",
       " 58,\n",
       " 1802,\n",
       " 1403,\n",
       " 1952,\n",
       " 1201,\n",
       " 1194]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_indices = val_data_sampler.batch_indices[0]\n",
    "batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, tokens, targets, lengths = get_batch(batch_indices, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(sentences, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 10, 193])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 函数 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp, tp_fp, tp_fn = measure(output, targets, lengths)\n",
    "assert output.size(0) == targets.size(0) and targets.size(0) == lengths.size(0)\n",
    "tp = 0\n",
    "tp_fp = 0\n",
    "tp_fn = 0\n",
    "batch_size = output.size(0)\n",
    "output_ = torch.argmax(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(batch_size):\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10, device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = lengths[i]\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 10])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = output_[i][:length].tolist()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 10])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0, 39,  0, 40,  0],\n",
       "        [ 0,  0,  0,  0, 23,  0,  0, 24,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 18, 22,  0, 23,  0],\n",
       "        [ 0,  0,  0, 24,  0,  0,  0, 23,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 24,  0, 23,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 87,  0, 88,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0, 24,  0, 23,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [18, 20, 22,  0,  0, 23,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = targets[i][:length].tolist()\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####### 函数 get_triplets #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_triplets\n",
    "# out_triplets = get_triplets(out)\n",
    "tags = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "triplets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tag in enumerate(tags):\n",
    "    if tag == tag_set[\"O\"]:\n",
    "        continue\n",
    "    pos, relation_label, role = tag_set[tag].split(\"-\")\n",
    "    if pos == \"B\" or pos == \"S\":\n",
    "        if relation_label not in temp:\n",
    "            temp[relation_label] = [[], []]\n",
    "        temp[relation_label][int(role) - 1].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation_label in temp:\n",
    "    role1, role2 = temp[relation_label]\n",
    "    if role1 and role2:\n",
    "        len1, len2 = len(role1), len(role2)\n",
    "        if len1 > len2:\n",
    "            for e2 in role2:\n",
    "                idx = np.argmin([abs(e2 - e1) for e1 in role1])\n",
    "                e1 = role1[idx]\n",
    "                triplets.append((e1, relation_label, e2))\n",
    "                del role1[idx]\n",
    "        else:\n",
    "            for e1 in role1:\n",
    "                idx = np.argmin([abs(e2 - e1) for e2 in role2])\n",
    "                e2 = role2[idx]\n",
    "                triplets.append((e1, relation_label, e2))\n",
    "                del role2[idx]\n",
    "# return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(tags):\n",
    "    temp = {}\n",
    "    triplets = []\n",
    "    for idx, tag in enumerate(tags):\n",
    "        if tag == tag_set[\"O\"]:\n",
    "            continue\n",
    "        pos, relation_label, role = tag_set[tag].split(\"-\")\n",
    "        if pos == \"B\" or pos == \"S\":\n",
    "            if relation_label not in temp:\n",
    "                temp[relation_label] = [[], []]\n",
    "            temp[relation_label][int(role) - 1].append(idx)\n",
    "    for relation_label in temp:\n",
    "        role1, role2 = temp[relation_label]\n",
    "        if role1 and role2:\n",
    "            len1, len2 = len(role1), len(role2)\n",
    "            if len1 > len2:\n",
    "                for e2 in role2:\n",
    "                    idx = np.argmin([abs(e2 - e1) for e1 in role1])\n",
    "                    e1 = role1[idx]\n",
    "                    triplets.append((e1, relation_label, e2))\n",
    "                    del role1[idx]\n",
    "            else:\n",
    "                for e1 in role1:\n",
    "                    idx = np.argmin([abs(e2 - e1) for e2 in role2])\n",
    "                    e2 = role2[idx]\n",
    "                    triplets.append((e1, relation_label, e2))\n",
    "                    del role2[idx]\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_triplets = get_triplets(out)\n",
    "tp_fp += len(out_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_triplets = get_triplets(target)\n",
    "tp_fn += len(target_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_triplet in target_triplets:\n",
    "    for out_triplet in out_triplets:\n",
    "        if out_triplet == target_triplet:\n",
    "            tp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(output, targets, lengths):\n",
    "    assert output.size(0) == targets.size(0) and targets.size(0) == lengths.size(0)\n",
    "    tp = 0\n",
    "    tp_fp = 0\n",
    "    tp_fn = 0\n",
    "    batch_size = output.size(0)\n",
    "    output = torch.argmax(output, dim=-1)\n",
    "    for i in range(batch_size):\n",
    "        length = lengths[i]\n",
    "        out = output[i][:length].tolist()\n",
    "        target = targets[i][:length].tolist()\n",
    "        out_triplets = get_triplets(out)\n",
    "        tp_fp += len(out_triplets)\n",
    "        target_triplets = get_triplets(target)\n",
    "        tp_fn += len(target_triplets)\n",
    "        for target_triplet in target_triplets:\n",
    "            for out_triplet in out_triplets:\n",
    "                if out_triplet == target_triplet:\n",
    "                    tp += 1\n",
    "    return tp, tp_fp, tp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP += tp\n",
    "TP_FP += tp_fp\n",
    "TP_FN += tp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pack_padded_sequence(output, lengths, batch_first=True).data\n",
    "targets = pack_padded_sequence(targets, lengths, batch_first=True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([154])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([154, 193])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3865.6277, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss += loss.item()\n",
    "count += len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 代码梳理及细节回顾(在VScode中演示)\n",
    "\n",
    "　　在VScode环境中的训练文件里再回顾训练流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 作业\n",
    "  \n",
    "`【思考题】`思考这篇文章的模型的不足，有什么可以改进的地方，是否还可以想到其他联合处理实体和关系抽取的新的框架。\n",
    "\n",
    "`【代码实践】`复现该文章代码的模型部分。\n",
    "\n",
    "`【画图】`不看文章原图，按照自己的理解画出模型的结构图。\n",
    "\n",
    "`【总结】`对这篇文章进行回顾，从描述背景，到提出模型，再到实验证明，思考并学习文章是如何将他们组合在一起的，学习文章的写作手法和思路。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTH_1.6",
   "language": "python",
   "name": "pyth_1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
